{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report: State of train mobility in Germany\n",
    "\n",
    "This report aims to analyze the current state of train mobility in Germany.\n",
    "\n",
    "- Where is the expansion or improvement of existing rail connections worth prioritising?\n",
    "- Where is already good train infrastructure, where should improvements be made fastly? \n",
    "\n",
    "For this purpose, connection times between different cities with different means of transport are analysed in this report. Secondly, an attempt is made to identify bootlenecks at train stations via a Deutsche Bahn timetable API.\n",
    "\n",
    "The structure of this report is as follows:\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Analysis of Dataset 1: Connection Times between German towns](#Analysis-of-dataset-1-connection-times-between-german-towns)\n",
    "3. [Analysis of Dataset 2: Delay causes for specific train stations](#Analysis-of-dataset-2-delay-causes-for-specific-train-stations)\n",
    "4. [Summary](#summary)\n",
    "\n",
    "This report is based on open data from two different datasources:\n",
    "\n",
    "### Datasource 1\n",
    "Datasource 1 holds a graph with the connection times between the 100 biggest towns in Germany by different means of transport. \n",
    "\n",
    "The Datasource 1 data is provided under a [Creative Commons Attribution 4.0 International (CC BY 4.0)0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "Datasource information:\n",
    "- Metadata URL: https://mobilithek.info/offers/573356838940979200\n",
    "- Data URL: https://mobilithek.info/mdp-api/files/aux/573356838940979200/moin-2022-05-02.1-20220502.131229-1.ttl.bz2\n",
    "- Data Type: RDF (Star) Graph, .ttl.bz2 - Archive\n",
    "\n",
    "### Datasource 2\n",
    "The second datasource is the DB Timetable API Version 1.0.x. The timetables API can be used to query information about the current (train) traffic situation in Germany and its causes. For the report an API endpoint is called that returns all known delay causes for a train station given by an *eva number* (train station identifier). \n",
    "\n",
    "For further information see the official website [DB API Marketplace - Timetables API](https://developers.deutschebahn.com/db-api-marketplace/apis/product/timetables) There you can find also the OpenAPI-document of the DB Timetable API.\n",
    "\n",
    "The Timetables APIs data is provided under a [Creative Commons Attribution 4.0 International (CC BY 4.0)0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "Datasource information:\n",
    "- Metadata URL: https://developers.deutschebahn.com/db-api-marketplace/apis/product/timetables/api/26494#/Timetables_10213/overview\n",
    "- Data URL: https://apis.deutschebahn.com/db-api-marketplace/apis/timetables/v1/\n",
    "- Data Type: API - application/xml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This section covers all requirements for the further Analysis of both datasets like the installation of dependencies and the loading of the datasets.\n",
    "\n",
    "Also it is shown which towns are cothered in both datasets and which towns are analyzed\n",
    "\n",
    "### Install dependencies\n",
    "Initially, install all required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.15.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly) (8.2.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->plotly) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SQLAlchemy in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.39)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy) (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat) (5.9.0)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat) (2.17.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat) (4.17.3)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from nbformat) (5.3.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.19.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=2.6->nbformat) (23.1.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core->nbformat) (306)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core->nbformat) (3.5.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (8.0.6)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (6.23.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (8.13.2)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (25.1.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (8.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.5)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: decorator in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.5.3)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (306)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install plotly\n",
    "%pip install SQLAlchemy\n",
    "%pip install nbformat\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Create a pandas dataframe using the local sqlite file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds1_df = pd.read_sql_table('connection_time_graph', 'sqlite:///project/data/train_connection_analysis.sqlite')\n",
    "ds2_df = pd.read_sql_table('timetable_for_stations', 'sqlite:///project/data/train_connection_analysis.sqlite')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Towns/Trainstops in Germany that are included in this analysis\n",
    "To show which towns/trainstops are included in our analysis, we use plotly to draw a scatterplot of all train stops in the dataset, overlaying it on a map from OpenStreetMap.\n",
    "\n",
    "To get the positions in the map of the towns we use the data from the dataset of exercise2 and the eva_numbers of dataset2.\n",
    "\n",
    "// The train stops will be colored based on the `Betreiber_Name`, allowing us to see what area an operator services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfig = px.scatter_mapbox(df, \\n                        lat=\"Breite\", \\n                        lon=\"Laenge\", \\n                        hover_name=\"NAME\", \\n                        hover_data=[\"EVA_NR\", \"DS100\", \"Betreiber_Name\"],\\n                        color=\"Betreiber_Name\",\\n                        zoom=5, \\n                        height=800,\\n                        width=1200)\\n\\nfig.update_layout(mapbox_style=\"open-street-map\")\\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\\nfig.show()'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "\n",
    "# pio.renderers.default = \"notebook\"\n",
    "\n",
    "\"\"\"\n",
    "fig = px.scatter_mapbox(df, \n",
    "                        lat=\"Breite\", \n",
    "                        lon=\"Laenge\", \n",
    "                        hover_name=\"NAME\", \n",
    "                        hover_data=[\"EVA_NR\", \"DS100\", \"Betreiber_Name\"],\n",
    "                        color=\"Betreiber_Name\",\n",
    "                        zoom=5, \n",
    "                        height=800,\n",
    "                        width=1200)\n",
    "\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Dataset 1: Connection Times between German towns\n",
    "The following chapter now covers the Analysis of Dataset 1.\n",
    "\n",
    "The question we like to answer here is which towns already have better or worser connection times to other towns in comparison the car connections times.\n",
    "\n",
    "We therefore query the graph from Dataset 1 that includes the connection times between every analyzed town with different means of transport like cars or trains."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of Dataset1\n",
    "Before diving into Analysis, we show the structure of the dataset to get a feeling about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of        index        id message_type     from_time       to_time  \\\n",
      "0          0  r1923001            h  2.303310e+09  2.306302e+09   \n",
      "1          1  r1961074            h  2.306232e+09  2.306260e+09   \n",
      "2          2  r1923001            h  2.303310e+09  2.306302e+09   \n",
      "3          3  r1982070            h  2.306232e+09  2.307122e+09   \n",
      "4          4  r1983704            h  2.306231e+09  2.306241e+09   \n",
      "...      ...       ...          ...           ...           ...   \n",
      "42998  17330  r1978875            h  2.306180e+09  2.307302e+09   \n",
      "42999  17331  r1978875            h  2.306180e+09  2.307302e+09   \n",
      "43000  17332  r1806644            h  2.212110e+09  2.312092e+09   \n",
      "43001  17333      None         None           NaN           NaN   \n",
      "43002  17334      None         None           NaN           NaN   \n",
      "\n",
      "                                 category     timestamp  priority  \\\n",
      "0      Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0   \n",
      "1      Bauarbeiten. (Quelle: zuginfo.nrw)  2.306061e+09       2.0   \n",
      "2      Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0   \n",
      "3      Bauarbeiten. (Quelle: zuginfo.nrw)  2.306202e+09       2.0   \n",
      "4          Störung. (Quelle: zuginfo.nrw)  2.306232e+09       1.0   \n",
      "...                                   ...           ...       ...   \n",
      "42998                         Information  2.306162e+09       2.0   \n",
      "42999                         Information  2.306162e+09       2.0   \n",
      "43000                         Information  2.211232e+09       2.0   \n",
      "43001                                None           NaN       NaN   \n",
      "43002                                None           NaN       NaN   \n",
      "\n",
      "         train_station  problems_found  del  \n",
      "0           Aachen Hbf            True  NaN  \n",
      "1           Aachen Hbf            True  NaN  \n",
      "2           Aachen Hbf            True  NaN  \n",
      "3           Aachen Hbf            True  NaN  \n",
      "4           Aachen Hbf            True  NaN  \n",
      "...                ...             ...  ...  \n",
      "42998           Dessau            True  NaN  \n",
      "42999           Dessau            True  NaN  \n",
      "43000           Dessau            True  NaN  \n",
      "43001  Saarbrücken Hbf           False  NaN  \n",
      "43002     Solingen Hbf           False  NaN  \n",
      "\n",
      "[43003 rows x 11 columns]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>message_type</th>\n",
       "      <th>from_time</th>\n",
       "      <th>to_time</th>\n",
       "      <th>category</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>priority</th>\n",
       "      <th>train_station</th>\n",
       "      <th>problems_found</th>\n",
       "      <th>del</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>r1923001</td>\n",
       "      <td>h</td>\n",
       "      <td>2.303310e+09</td>\n",
       "      <td>2.306302e+09</td>\n",
       "      <td>Bauarbeiten. (Quelle: zuginfo.nrw)</td>\n",
       "      <td>2.304052e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>r1961074</td>\n",
       "      <td>h</td>\n",
       "      <td>2.306232e+09</td>\n",
       "      <td>2.306260e+09</td>\n",
       "      <td>Bauarbeiten. (Quelle: zuginfo.nrw)</td>\n",
       "      <td>2.306061e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        id message_type     from_time       to_time  \\\n",
       "0      0  r1923001            h  2.303310e+09  2.306302e+09   \n",
       "1      1  r1961074            h  2.306232e+09  2.306260e+09   \n",
       "\n",
       "                             category     timestamp  priority train_station  \\\n",
       "0  Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0    Aachen Hbf   \n",
       "1  Bauarbeiten. (Quelle: zuginfo.nrw)  2.306061e+09       2.0    Aachen Hbf   \n",
       "\n",
       "   problems_found  del  \n",
       "0            True  NaN  \n",
       "1            True  NaN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ds2_df.info)\n",
    "ds2_df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection Times for a specific connection\n",
    "To answer the question of the connection times about a specific connection in detail, we make details for a specific connection accessible. At first we show the information as it is in the dataset. Then we will aggregate the data by towns and calculate metrics to compare train and car connections by town.\n",
    "\n",
    "Just select your \\<Source\\> and your \\<Destination\\>. It will show the duration in minutes for a possible connection and the transportType of the connection.\n",
    "\n",
    "Note: There are different train connections with different connection times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8502dddbb94053aacc99d2c83d9c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='source', options=('Aachen', 'Augsburg', 'Berlin', 'Bielefeld', 'Bo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "sources = list(ds1_df[\"source\"].unique())\n",
    "destinations = list(ds1_df[\"destination\"].unique())\n",
    "\n",
    "@interact\n",
    "def show_basic_connection_information(source=sources,\n",
    "                                destination=destinations):\n",
    "    connection = ds1_df[(ds1_df[\"source\"] == source) & (ds1_df[\"destination\"] == destination)]\n",
    "    connection = connection[[\"source\", \"destination\", \"duration\", \"transportType\"]]\n",
    "    connection[\"duration\"] = pd.to_datetime(connection.duration, unit='m').dt.strftime('%Hh %Mmin')\n",
    "    print(connection)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate connection times per connection into a single row and calculate mean/min train duration\n",
    "\n",
    "To answer the question where are already good train connections, we need to compare the connection times by car with them by train. Therefore we pick the fastest train connection and the median and compare connection times to the ones by car. We store the information for a specific connection in a single row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   source destination  median_train_duration  min_train_duration  car_duration\n",
      "0  Aachen    Augsburg                  314.0                 302           318\n",
      "1  Aachen      Berlin                  356.0                 351           352\n"
     ]
    }
   ],
   "source": [
    "# Select the train connections, group the trains connections by 'source' and 'destination' and calculate the median and minimum duration\n",
    "train_df = ds1_df[ds1_df['transportType'] == 'train']\n",
    "train_grouped = train_df.groupby(['source', 'destination'])['duration'].agg(['median', 'min']).reset_index()\n",
    "\n",
    "# Filter the DataFrame for 'car' durations\n",
    "car_df = ds1_df[ds1_df['transportType'] == 'car']\n",
    "car_df = car_df[[\"source\", \"destination\", \"duration\"]]\n",
    "#print(car_df)\n",
    "\n",
    "# Merge the train_df and car_df on 'source' and 'destination'\n",
    "connection_times_df = pd.merge(train_grouped, car_df, on=['source', 'destination'], how='left')\n",
    "\n",
    "# Rename the columns\n",
    "connection_times_df.rename(columns={'median': 'median_train_duration', 'min': 'min_train_duration', 'duration': 'car_duration'}, inplace=True)\n",
    "\n",
    "print(connection_times_df.head(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare train connection times with car connection times\n",
    "To answer the question where a train connection is already better than a car connection, calculate the difference of the connection times. \n",
    "\n",
    "* Positive values x mean that a train connection is faster by x minutes than the car connection between a source and a destination.\n",
    "* Negative values x mean that a train connection is slower by x minutes than the car connection between a source and a destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   source destination  median_train_duration  min_train_duration  \\\n",
      "0  Aachen    Augsburg                  314.0                 302   \n",
      "1  Aachen      Berlin                  356.0                 351   \n",
      "\n",
      "   car_duration  diff_car_median_train_duration  diff_car_min_train_duration  \n",
      "0           318                             4.0                           16  \n",
      "1           352                            -4.0                            1  \n"
     ]
    }
   ],
   "source": [
    "connection_times_df[\"diff_car_median_train_duration\"] = connection_times_df[\"car_duration\"] - connection_times_df[\"median_train_duration\"]\n",
    "connection_times_df[\"diff_car_min_train_duration\"] = connection_times_df[\"car_duration\"] - connection_times_df[\"min_train_duration\"]\n",
    "\n",
    "print(connection_times_df.head(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show metrics for a specific connection\n",
    "\n",
    "Now we can show the calculated metrics for a specific connection and show which transportation type is faster for a specific connection between two towns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3d7dc118a845459d20dd1b5ef8569e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='source', options=('Aachen', 'Augsburg', 'Berlin', 'Bielefeld', 'Bo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remember, we calculated the sources and destinations list for the dropbox earlier\n",
    "\n",
    "@interact\n",
    "def show_metrics_for_a_connection(source=sources,\n",
    "                                destination=destinations):\n",
    "    connection = connection_times_df[(connection_times_df[\"source\"] == source) & (connection_times_df[\"destination\"] == destination)]\n",
    "    print(connection)\n",
    "    diff_car_min_train_duration = connection[\"diff_car_min_train_duration\"].values[0]\n",
    "    diff_car_median_train_duration = connection[\"diff_car_median_train_duration\"].values[0]\n",
    "    \n",
    "    if diff_car_min_train_duration > 0:\n",
    "        print(f\"\\nThe fastest train connection from {source} to {destination} is {diff_car_min_train_duration} minutes faster than the car connection.\")\n",
    "    else:\n",
    "        print(f\"\\nThe fastest train connection from {source} to {destination} is {diff_car_min_train_duration} minutes slower than the car connection.\")\n",
    "    \n",
    "    if diff_car_median_train_duration > 0:\n",
    "        print(f\"\\nThe median train connection from {source} to {destination} is {diff_car_median_train_duration} minutes faster than the car connection.\")\n",
    "    else:\n",
    "        print(f\"\\nThe median train connection from {source} to {destination} is {diff_car_median_train_duration} minutes slower than the car connection.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking of towns with good train connections\n",
    "\n",
    "To show which towns already have good train connections we now calculate for all outgoing connections from a town if the car or the train is faster to all destinations and count the results. We then create a ranking to highlight towns that are better accessible by car and towns that are better accessible by train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_train_faster = connection_times_df.groupby(\"source\")[\"diff_car_min_train_duration\"].apply(lambda diff_car_min_train_duration: (diff_car_min_train_duration > 0).sum()).reset_index(name=\"min_train_faster\")\n",
    "median_train_faster = connection_times_df.groupby(\"source\")[\"diff_car_median_train_duration\"].apply(lambda diff_car_min_train_duration: (diff_car_min_train_duration > 0).sum()).reset_index(name=\"median_train_faster\")\n",
    "\n",
    "town_ranking = pd.merge(min_train_faster, median_train_faster, on=\"source\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Towns sorted by the number of outgoing connections where the **fastest** train connection is faster than the car connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    source  min_train_faster  median_train_faster\n",
      "2                   Berlin                57                   26\n",
      "44                Mannheim                47                   38\n",
      "64               Stuttgart                43                   24\n",
      "1                 Augsburg                42                   18\n",
      "33               Karlsruhe                40                   11\n",
      "..                     ...               ...                  ...\n",
      "35                    Kiel                 1                    0\n",
      "68  Villingen-Schwenningen                 0                    0\n",
      "65                   Trier                 0                    0\n",
      "19               Flensburg                 0                    0\n",
      "37                Konstanz                 0                    0\n",
      "\n",
      "[75 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "town_ranking.sort_values(by=[\"min_train_faster\"], inplace=True, ascending=False)\n",
    "print(town_ranking)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Towns sorted by the number of outgoing connections where the **median** train connection is faster than the car connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    source  min_train_faster  median_train_faster\n",
      "44                Mannheim                47                   38\n",
      "2                   Berlin                57                   26\n",
      "64               Stuttgart                43                   24\n",
      "15                Duisburg                32                   21\n",
      "30              Ingolstadt                35                   20\n",
      "..                     ...               ...                  ...\n",
      "35                    Kiel                 1                    0\n",
      "68  Villingen-Schwenningen                 0                    0\n",
      "65                   Trier                 0                    0\n",
      "19               Flensburg                 0                    0\n",
      "37                Konstanz                 0                    0\n",
      "\n",
      "[75 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "town_ranking.sort_values(by=[\"median_train_faster\"], inplace=True, ascending=False)\n",
    "print(town_ranking)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Dataset 2: Delay causes for specific train stations\n",
    "\n",
    "In the following chapter we provide details which train stations have more problems than others to identify possible bottlenecks. \n",
    "\n",
    "### Structure of Dataset 2\n",
    "Also for Dataset 2 we first show the structure of the Dataset to get insights into the data structre. As the data pipeline for dataset 2 runs multiple times duplicates are theoretically possible, so we also again drop duplicates to be sure that no duplicates are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of        index        id message_type     from_time       to_time  \\\n",
      "0          0  r1923001            h  2.303310e+09  2.306302e+09   \n",
      "1          1  r1961074            h  2.306232e+09  2.306260e+09   \n",
      "3          3  r1982070            h  2.306232e+09  2.307122e+09   \n",
      "4          4  r1983704            h  2.306231e+09  2.306241e+09   \n",
      "7          7  r1978334            h  2.306160e+09  2.307282e+09   \n",
      "...      ...       ...          ...           ...           ...   \n",
      "42995  17327  r1985306            h  2.306241e+09  2.307012e+09   \n",
      "42996  17328  r1971077            h  2.306102e+09  2.307012e+09   \n",
      "43000  17332  r1806644            h  2.212110e+09  2.312092e+09   \n",
      "43001  17333      None         None           NaN           NaN   \n",
      "43002  17334      None         None           NaN           NaN   \n",
      "\n",
      "                                 category     timestamp  priority  \\\n",
      "0      Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0   \n",
      "1      Bauarbeiten. (Quelle: zuginfo.nrw)  2.306061e+09       2.0   \n",
      "3      Bauarbeiten. (Quelle: zuginfo.nrw)  2.306202e+09       2.0   \n",
      "4          Störung. (Quelle: zuginfo.nrw)  2.306232e+09       1.0   \n",
      "7                             Information  2.306162e+09       2.0   \n",
      "...                                   ...           ...       ...   \n",
      "42995                         Information  2.306241e+09       3.0   \n",
      "42996                         Information  2.306071e+09       1.0   \n",
      "43000                         Information  2.211232e+09       2.0   \n",
      "43001                                None           NaN       NaN   \n",
      "43002                                None           NaN       NaN   \n",
      "\n",
      "         train_station  problems_found  del  \n",
      "0           Aachen Hbf            True  NaN  \n",
      "1           Aachen Hbf            True  NaN  \n",
      "3           Aachen Hbf            True  NaN  \n",
      "4           Aachen Hbf            True  NaN  \n",
      "7           Aachen Hbf            True  NaN  \n",
      "...                ...             ...  ...  \n",
      "42995           Dessau            True  NaN  \n",
      "42996           Dessau            True  NaN  \n",
      "43000           Dessau            True  NaN  \n",
      "43001  Saarbrücken Hbf           False  NaN  \n",
      "43002     Solingen Hbf           False  NaN  \n",
      "\n",
      "[12133 rows x 11 columns]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>message_type</th>\n",
       "      <th>from_time</th>\n",
       "      <th>to_time</th>\n",
       "      <th>category</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>priority</th>\n",
       "      <th>train_station</th>\n",
       "      <th>problems_found</th>\n",
       "      <th>del</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>r1923001</td>\n",
       "      <td>h</td>\n",
       "      <td>2.303310e+09</td>\n",
       "      <td>2.306302e+09</td>\n",
       "      <td>Bauarbeiten. (Quelle: zuginfo.nrw)</td>\n",
       "      <td>2.304052e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>r1961074</td>\n",
       "      <td>h</td>\n",
       "      <td>2.306232e+09</td>\n",
       "      <td>2.306260e+09</td>\n",
       "      <td>Bauarbeiten. (Quelle: zuginfo.nrw)</td>\n",
       "      <td>2.306061e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        id message_type     from_time       to_time  \\\n",
       "0      0  r1923001            h  2.303310e+09  2.306302e+09   \n",
       "1      1  r1961074            h  2.306232e+09  2.306260e+09   \n",
       "\n",
       "                             category     timestamp  priority train_station  \\\n",
       "0  Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0    Aachen Hbf   \n",
       "1  Bauarbeiten. (Quelle: zuginfo.nrw)  2.306061e+09       2.0    Aachen Hbf   \n",
       "\n",
       "   problems_found  del  \n",
       "0            True  NaN  \n",
       "1            True  NaN  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2_df = ds2_df.drop_duplicates(subset=[\"id\", \"message_type\", \"from_time\", \"to_time\", \"category\", \"timestamp\", \"priority\", \"train_station\", \"problems_found\", \"del\"])\n",
    "print(ds2_df.info)\n",
    "ds2_df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stations with no found problems\n",
    "\n",
    "The column problems_found indicates wether there are problems found for a station while querying the DB Api or not. \n",
    "\n",
    "We show them separatly as these are stations whose Analysis differ from the Analysis of other stations. As the query is empty every station seems to have an entry with problems in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index    id message_type  from_time  to_time category  timestamp  \\\n",
      "43001  17333  None         None        NaN      NaN     None        NaN   \n",
      "43002  17334  None         None        NaN      NaN     None        NaN   \n",
      "\n",
      "       priority    train_station  problems_found  del  \n",
      "43001       NaN  Saarbrücken Hbf           False  NaN  \n",
      "43002       NaN     Solingen Hbf           False  NaN  \n"
     ]
    }
   ],
   "source": [
    "none_delay_stations = ds2_df[ds2_df[\"problems_found\"] == False]\n",
    "print(none_delay_stations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delay causes in the dataset\n",
    "\n",
    "In the dataset is a column \"category\" for the delay causes. Not all entries seem to be real delays. Also included is a category *Information*. \n",
    "\n",
    "The following delay causes are present in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bauarbeiten. (Quelle: zuginfo.nrw)', 'Störung. (Quelle: zuginfo.nrw)', 'Information', 'Störung', None, 'Bauarbeiten', 'Information. (Quelle: zuginfo.nrw)', 'Großstörung']\n"
     ]
    }
   ],
   "source": [
    "delay_causes = list(ds2_df[\"category\"].unique())\n",
    "print(delay_causes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The german federal state Nrw seems to have its own cause type. As this information is not relevant for us in the following analysis, we remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bauarbeiten', 'Störung', 'Information', None, 'Großstörung']\n"
     ]
    }
   ],
   "source": [
    "ds2_df[\"category\"] = ds2_df[\"category\"].str.split('.').str[0]\n",
    "delay_causes = list(ds2_df[\"category\"].unique())\n",
    "print(delay_causes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delays in the operation of a specific train station\n",
    "As for connections also the information of Datasource 2 should be able to be filtered. Just select your \\<Station\\> and a \\<Delay cause\\> to make delay causes visible for a specific station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a97b9f2ad0465ab9c3a44e56cdf437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='train_station', options=('Aachen Hbf', 'Augsburg Hbf', 'Berlin Hbf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stations = list(ds2_df[\"train_station\"].unique())\n",
    "\n",
    "@interact\n",
    "def show_train_station_information(train_station=stations, delay_cause=delay_causes):\n",
    "    station = ds2_df[(ds2_df[\"train_station\"] == train_station) & (ds2_df[\"problems_found\"] == True)]\n",
    "    if(station.empty):\n",
    "        print(\"No problems for station \", train_station, \" found!\")\n",
    "    else:\n",
    "        station = station[[\"train_station\", \"from_time\", \"to_time\", \"category\", \"priority\"]]\n",
    "        station = station[station[\"category\"] == delay_cause]\n",
    "        station[\"from_time\"] = pd.to_datetime(station[\"from_time\"], format='%y%m%d%H%M')\n",
    "        station[\"to_time\"] = pd.to_datetime(station[\"to_time\"], format='%y%m%d%H%M')\n",
    "        station[\"duration\"] = station[\"to_time\"] - station[\"from_time\"]\n",
    "        print(station)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition of the delay duration by Category\n",
    "To rank stations according to their vulnerability to interferences coefficients have to be calculated for each station. As the severity of interferences differ by category we group by category. \n",
    "\n",
    "In the following coefficients like total delay duration, average delay duration and number of delays for each station by category are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting by Category\n",
    "Different Categories are different meaningful. It is likely that a *Großstörung (engl. major disturbance)* has more severe causes than a *Störung (engl. disturbance)*. *Bauarbeiten (engl. construction work)* is also a delay cause, but one that might lead to lesser delays in the future. *Information*s seem to be harmless. We assume the following severty order:\n",
    "1. *Großstörung*\n",
    "2. *Störung*\n",
    "3. *Bauarbeiten*\n",
    "4. *Information*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking of Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this last chapter we summarize our results by presenting our findings again. Furthermore we also like to indicate on which major assumptions these findings are based. Then we briefly sum up the most difficult problems tackled in the project. Finally we give an outlook how the project can be extended and how the certainty of the results can be further improved.\n",
    "\n",
    "### Findings\n",
    "\n",
    "#### Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions\n",
    "This section should briefly cover the most important assumptions that were made.\n",
    "\n",
    "#### The more delays the worse the station\n",
    "The findings in Datasource 2 require the assumption that the more delays a station has the worse the station is. This might not always be true. It is rather likely that f.e. the station Berlin Hbf has more delays than the station of Rostock. But for towns that have stations that have a comparable train frequency this assumption is likely to be true.\n",
    "\n",
    "#### One station per town\n",
    "For a town only the central train station was considered in Dataset 2, not all stations of a town.\n",
    "\n",
    "### Problems during the whole Project\n",
    "\n",
    "#### Corrupted ttl file of Datasource 1\n",
    "The most severe problem tackeled during the project was that Datasource 1 provides corrupted data. The ttl file containing the rdf graph with the connection times between the towns is syntactically false. Therefore a preprocessing was required before the graph could be parsed. The preprocessing contains replacing expressions using regexes and removing invalid signs. \n",
    "\n",
    "A relation in rdf basically consists of a triple of a *\\<subject\\>*, *\\<predicate\\>* and an *\\<object\\>* like f.e. *Erlangen* *IsConnectedTo* *Berlin*. \n",
    "\n",
    "The relation between source and destination with attributes like the driving time was also not correctly associated in rdf terms in the ttl file. For this reason attributes also had to be brought into relation with the corresponding connection by complex logical changes in the rdf file. \n",
    "\n",
    "By these changes the attributes could be brought into relation to its connection and the graph could be parsed correctly with rdflib.\n",
    "\n",
    "#### Contineous updates of Datasource 2\n",
    "Another problem was that the DB Timetable API provides potentially new informations every 30 minutes. Nethertheless some informations do not change that often (f.e. the delay cause *Bauarbeiten* are a time consuming task that lasts from days to months). Therefore one problem is the deduplication of events that were grasped multiple times. Also would it be nice to grasp the data contineously like f.e. every hour, but this what require an installation on a server that automatically calls the API as a scheduled task. This was not possible manually.\n",
    "\n",
    "#### XML representation of the data of Datasource 2\n",
    "The used endpoint of the DB Timetable API of Datasource 2 provides more information than just the delay causes in a XML representation. To retrieve only the needed data a XPATH query was used. \n",
    "\n",
    "### Outlook\n",
    "#### Contineous grasping of data from Datasource 2\n",
    "The actual dataset from Datasource 2 covers at the moment data of four different days. The data was requested about approximately the same time. An interesting enhancement would be to deploy the model to a server with much storage and call the DB Api automatically daily or hourly over a long time like f.e. a year. The current data is just a snapshot of the current state. Maybe it can be found that in the long term other stations are the ones that are the most potential for enhancements.\n",
    "\n",
    "#### Including multiple stations per town\n",
    "Some towns have multiple stations. In this report only the main train station of a town is covered. Covering other stations of towns in Dataset 2 would also provide further information.\n",
    "\n",
    "#### Comparing train connection times of Datasource 1 with real-time information of the DB Timetable API\n",
    "Furthermore the DB Timetable API provides other endpoints that provide further information of current connections. It would be interesting to compare the real average train connection times with the train connection times provided in Dataset 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Destination/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
