{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report: State of train mobility in Germany\n",
    "\n",
    "This report aims to analyze the current state of train mobility in Germany.\n",
    "\n",
    "- Where is the expansion or improvement of existing rail connections worth prioritising?\n",
    "- Where is already good train infrastructure, where should improvements be made fastly? \n",
    "\n",
    "For this purpose, connection times between different cities with different means of transport are analysed in this report. Secondly, an attempt is made to identify bootlenecks at train stations via a Deutsche Bahn timetable API.\n",
    "\n",
    "The structure of this report is as follows:\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Analysis of Dataset 1: Connection Times between German towns](#Analysis-of-dataset-1-connection-times-between-german-towns)\n",
    "3. [Analysis of Dataset 2: Delay causes for specific train stations](#Analysis-of-dataset-2-delay-causes-for-specific-train-stations)\n",
    "4. [Summary](#summary)\n",
    "\n",
    "This report is based on open data from two different datasources:\n",
    "\n",
    "### Datasource 1\n",
    "Datasource 1 holds a graph with the connection times between the 100 biggest towns in Germany by different means of transport. \n",
    "\n",
    "The Datasource 1 data is provided under a [Creative Commons Attribution 4.0 International (CC BY 4.0)0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "Datasource information:\n",
    "- Metadata URL: https://mobilithek.info/offers/573356838940979200\n",
    "- Data URL: https://mobilithek.info/mdp-api/files/aux/573356838940979200/moin-2022-05-02.1-20220502.131229-1.ttl.bz2\n",
    "- Data Type: RDF (Star) Graph, .ttl.bz2 - Archive\n",
    "\n",
    "### Datasource 2\n",
    "The second datasource is the DB Timetable API Version 1.0.x. The timetables API can be used to query information about the current (train) traffic situation in Germany and its causes. For the report an API endpoint is called that returns all known delay causes for a train station given by an *eva number* (train station identifier). \n",
    "\n",
    "For further information see the official website [DB API Marketplace - Timetables API](https://developers.deutschebahn.com/db-api-marketplace/apis/product/timetables) There you can find also the OpenAPI-document of the DB Timetable API.\n",
    "\n",
    "The Timetables APIs data is provided under a [Creative Commons Attribution 4.0 International (CC BY 4.0)0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "Datasource information:\n",
    "- Metadata URL: https://developers.deutschebahn.com/db-api-marketplace/apis/product/timetables/api/26494#/Timetables_10213/overview\n",
    "- Data URL: https://apis.deutschebahn.com/db-api-marketplace/apis/timetables/v1/\n",
    "- Data Type: API - application/xml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This section covers all requirements for the further Analysis of both datasets like the installation of dependencies and the loading of the datasets.\n",
    "\n",
    "Also it is shown which towns are cothered in both datasets and which towns are analyzed\n",
    "\n",
    "### Install dependencies\n",
    "Initially, install all required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.15.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly) (8.2.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->plotly) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SQLAlchemy in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.39)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy) (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat) (2.17.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat) (5.9.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from nbformat) (5.3.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat) (4.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=2.6->nbformat) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.19.3)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core->nbformat) (306)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core->nbformat) (3.5.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (8.0.6)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (8.13.2)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (6.23.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (25.1.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (8.2.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.5)\n",
      "Requirement already satisfied: stack-data in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: decorator in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.5.3)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (306)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install plotly\n",
    "%pip install SQLAlchemy\n",
    "%pip install nbformat\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Create a pandas dataframe using the local sqlite file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds1_df = pd.read_sql_table('connection_time_graph', 'sqlite:///project/data/train_connection_analysis.sqlite')\n",
    "ds2_df = pd.read_sql_table('timetable_for_stations', 'sqlite:///project/data/train_connection_analysis.sqlite')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Dataset 1: Connection Times between German towns\n",
    "The following chapter now covers the Analysis of Dataset 1.\n",
    "\n",
    "The question we like to answer here is which towns already have better or worser connection times to other towns in comparison the car connections times.\n",
    "\n",
    "We therefore query the graph from Dataset 1 that includes the connection times between every analyzed town with different means of transport like cars or trains."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of Dataset1\n",
    "Before diving into Analysis, we show the structure of the dataset to get a feeling about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of        index        id message_type     from_time       to_time  \\\n",
      "0          0  r1923001            h  2.303310e+09  2.306302e+09   \n",
      "1          1  r1961074            h  2.306232e+09  2.306260e+09   \n",
      "2          2  r1923001            h  2.303310e+09  2.306302e+09   \n",
      "3          3  r1982070            h  2.306232e+09  2.307122e+09   \n",
      "4          4  r1983704            h  2.306231e+09  2.306241e+09   \n",
      "...      ...       ...          ...           ...           ...   \n",
      "42998  17330  r1978875            h  2.306180e+09  2.307302e+09   \n",
      "42999  17331  r1978875            h  2.306180e+09  2.307302e+09   \n",
      "43000  17332  r1806644            h  2.212110e+09  2.312092e+09   \n",
      "43001  17333      None         None           NaN           NaN   \n",
      "43002  17334      None         None           NaN           NaN   \n",
      "\n",
      "                                 category     timestamp  priority  \\\n",
      "0      Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0   \n",
      "1      Bauarbeiten. (Quelle: zuginfo.nrw)  2.306061e+09       2.0   \n",
      "2      Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0   \n",
      "3      Bauarbeiten. (Quelle: zuginfo.nrw)  2.306202e+09       2.0   \n",
      "4          Störung. (Quelle: zuginfo.nrw)  2.306232e+09       1.0   \n",
      "...                                   ...           ...       ...   \n",
      "42998                         Information  2.306162e+09       2.0   \n",
      "42999                         Information  2.306162e+09       2.0   \n",
      "43000                         Information  2.211232e+09       2.0   \n",
      "43001                                None           NaN       NaN   \n",
      "43002                                None           NaN       NaN   \n",
      "\n",
      "         train_station  problems_found  del  \n",
      "0           Aachen Hbf            True  NaN  \n",
      "1           Aachen Hbf            True  NaN  \n",
      "2           Aachen Hbf            True  NaN  \n",
      "3           Aachen Hbf            True  NaN  \n",
      "4           Aachen Hbf            True  NaN  \n",
      "...                ...             ...  ...  \n",
      "42998           Dessau            True  NaN  \n",
      "42999           Dessau            True  NaN  \n",
      "43000           Dessau            True  NaN  \n",
      "43001  Saarbrücken Hbf           False  NaN  \n",
      "43002     Solingen Hbf           False  NaN  \n",
      "\n",
      "[43003 rows x 11 columns]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>message_type</th>\n",
       "      <th>from_time</th>\n",
       "      <th>to_time</th>\n",
       "      <th>category</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>priority</th>\n",
       "      <th>train_station</th>\n",
       "      <th>problems_found</th>\n",
       "      <th>del</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>r1923001</td>\n",
       "      <td>h</td>\n",
       "      <td>2.303310e+09</td>\n",
       "      <td>2.306302e+09</td>\n",
       "      <td>Bauarbeiten. (Quelle: zuginfo.nrw)</td>\n",
       "      <td>2.304052e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>r1961074</td>\n",
       "      <td>h</td>\n",
       "      <td>2.306232e+09</td>\n",
       "      <td>2.306260e+09</td>\n",
       "      <td>Bauarbeiten. (Quelle: zuginfo.nrw)</td>\n",
       "      <td>2.306061e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        id message_type     from_time       to_time  \\\n",
       "0      0  r1923001            h  2.303310e+09  2.306302e+09   \n",
       "1      1  r1961074            h  2.306232e+09  2.306260e+09   \n",
       "\n",
       "                             category     timestamp  priority train_station  \\\n",
       "0  Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0    Aachen Hbf   \n",
       "1  Bauarbeiten. (Quelle: zuginfo.nrw)  2.306061e+09       2.0    Aachen Hbf   \n",
       "\n",
       "   problems_found  del  \n",
       "0            True  NaN  \n",
       "1            True  NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ds2_df.info)\n",
    "ds2_df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection Times for a specific connection\n",
    "To answer the question of the connection times about a specific connection in detail, we make details for a specific connection accessible. At first we show the information as it is in the dataset. Then we will aggregate the data by towns and calculate metrics to compare train and car connections by town.\n",
    "\n",
    "Just select your \\<Source\\> and your \\<Destination\\>. It will show the duration in minutes for a possible connection and the transportType of the connection.\n",
    "\n",
    "Note: There are different train connections with different connection times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caaacea9d1004bd1866bca65e9386c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='source', options=('Aachen', 'Augsburg', 'Berlin', 'Bielefeld', 'Bo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "sources = list(ds1_df[\"source\"].unique())\n",
    "destinations = list(ds1_df[\"destination\"].unique())\n",
    "\n",
    "@interact\n",
    "def show_basic_connection_information(source=sources,\n",
    "                                destination=destinations):\n",
    "    connection = ds1_df[(ds1_df[\"source\"] == source) & (ds1_df[\"destination\"] == destination)]\n",
    "    connection = connection[[\"source\", \"destination\", \"duration\", \"transportType\"]]\n",
    "    connection[\"duration\"] = pd.to_datetime(connection.duration, unit='m').dt.strftime('%Hh %Mmin')\n",
    "    print(connection)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate connection times per connection into a single row and calculate mean/min train duration\n",
    "\n",
    "To answer the question where are already good train connections, we need to compare the connection times by car with them by train. Therefore we pick the fastest train connection and the median and compare connection times to the ones by car. We store the information for a specific connection in a single row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   source destination  median_train_duration  min_train_duration  car_duration\n",
      "0  Aachen    Augsburg                  314.0                 302           318\n",
      "1  Aachen      Berlin                  356.0                 351           352\n"
     ]
    }
   ],
   "source": [
    "# Select the train connections, group the trains connections by 'source' and 'destination' and calculate the median and minimum duration\n",
    "train_df = ds1_df[ds1_df['transportType'] == 'train']\n",
    "train_grouped = train_df.groupby(['source', 'destination'])['duration'].agg(['median', 'min']).reset_index()\n",
    "\n",
    "# Filter the DataFrame for 'car' durations\n",
    "car_df = ds1_df[ds1_df['transportType'] == 'car']\n",
    "car_df = car_df[[\"source\", \"destination\", \"duration\"]]\n",
    "#print(car_df)\n",
    "\n",
    "# Merge the train_df and car_df on 'source' and 'destination'\n",
    "connection_times_df = pd.merge(train_grouped, car_df, on=['source', 'destination'], how='left')\n",
    "\n",
    "# Rename the columns\n",
    "connection_times_df.rename(columns={'median': 'median_train_duration', 'min': 'min_train_duration', 'duration': 'car_duration'}, inplace=True)\n",
    "\n",
    "print(connection_times_df.head(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare train connection times with car connection times\n",
    "To answer the question where a train connection is already better than a car connection, calculate the difference of the connection times. \n",
    "\n",
    "* Positive values x mean that a train connection is faster by x minutes than the car connection between a source and a destination.\n",
    "* Negative values x mean that a train connection is slower by x minutes than the car connection between a source and a destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   source destination  median_train_duration  min_train_duration  \\\n",
      "0  Aachen    Augsburg                  314.0                 302   \n",
      "1  Aachen      Berlin                  356.0                 351   \n",
      "\n",
      "   car_duration  diff_car_median_train_duration  diff_car_min_train_duration  \n",
      "0           318                             4.0                           16  \n",
      "1           352                            -4.0                            1  \n"
     ]
    }
   ],
   "source": [
    "connection_times_df[\"diff_car_median_train_duration\"] = connection_times_df[\"car_duration\"] - connection_times_df[\"median_train_duration\"]\n",
    "connection_times_df[\"diff_car_min_train_duration\"] = connection_times_df[\"car_duration\"] - connection_times_df[\"min_train_duration\"]\n",
    "\n",
    "print(connection_times_df.head(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show metrics for a specific connection\n",
    "\n",
    "Now we can show the calculated metrics for a specific connection and show which transportation type is faster for a specific connection between two towns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdbc258abbaa44abaf57ff234f51d351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='source', options=('Aachen', 'Augsburg', 'Berlin', 'Bielefeld', 'Bo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remember, we calculated the sources and destinations list for the dropbox earlier\n",
    "\n",
    "@interact\n",
    "def show_metrics_for_a_connection(source=sources,\n",
    "                                destination=destinations):\n",
    "    connection = connection_times_df[(connection_times_df[\"source\"] == source) & (connection_times_df[\"destination\"] == destination)]\n",
    "    print(connection)\n",
    "    diff_car_min_train_duration = connection[\"diff_car_min_train_duration\"].values[0]\n",
    "    diff_car_median_train_duration = connection[\"diff_car_median_train_duration\"].values[0]\n",
    "    \n",
    "    if diff_car_min_train_duration > 0:\n",
    "        print(f\"\\nThe fastest train connection from {source} to {destination} is {diff_car_min_train_duration} minutes faster than the car connection.\")\n",
    "    else:\n",
    "        print(f\"\\nThe fastest train connection from {source} to {destination} is {diff_car_min_train_duration} minutes slower than the car connection.\")\n",
    "    \n",
    "    if diff_car_median_train_duration > 0:\n",
    "        print(f\"\\nThe median train connection from {source} to {destination} is {diff_car_median_train_duration} minutes faster than the car connection.\")\n",
    "    else:\n",
    "        print(f\"\\nThe median train connection from {source} to {destination} is {diff_car_median_train_duration} minutes slower than the car connection.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking of towns with good train connections\n",
    "\n",
    "To show which towns already have good train connections we now calculate for all outgoing connections from a town if the car or the train is faster to all destinations and count the results. We then create a ranking to highlight towns that are better accessible by car and towns that are better accessible by train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_train_faster = connection_times_df.groupby(\"source\")[\"diff_car_min_train_duration\"].apply(lambda diff_car_min_train_duration: (diff_car_min_train_duration > 0).sum()).reset_index(name=\"min_train_faster\")\n",
    "median_train_faster = connection_times_df.groupby(\"source\")[\"diff_car_median_train_duration\"].apply(lambda diff_car_min_train_duration: (diff_car_min_train_duration > 0).sum()).reset_index(name=\"median_train_faster\")\n",
    "\n",
    "town_ranking = pd.merge(min_train_faster, median_train_faster, on=\"source\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Towns sorted by the number of outgoing connections where the **fastest** train connection is faster than the car connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    source  min_train_faster  median_train_faster\n",
      "2                   Berlin                57                   26\n",
      "44                Mannheim                47                   38\n",
      "64               Stuttgart                43                   24\n",
      "1                 Augsburg                42                   18\n",
      "33               Karlsruhe                40                   11\n",
      "..                     ...               ...                  ...\n",
      "35                    Kiel                 1                    0\n",
      "68  Villingen-Schwenningen                 0                    0\n",
      "65                   Trier                 0                    0\n",
      "19               Flensburg                 0                    0\n",
      "37                Konstanz                 0                    0\n",
      "\n",
      "[75 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "town_ranking.sort_values(by=[\"min_train_faster\"], inplace=True, ascending=False)\n",
    "print(town_ranking)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Towns sorted by the number of outgoing connections where the **median** train connection is faster than the car connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    source  min_train_faster  median_train_faster\n",
      "44                Mannheim                47                   38\n",
      "2                   Berlin                57                   26\n",
      "64               Stuttgart                43                   24\n",
      "15                Duisburg                32                   21\n",
      "30              Ingolstadt                35                   20\n",
      "..                     ...               ...                  ...\n",
      "35                    Kiel                 1                    0\n",
      "68  Villingen-Schwenningen                 0                    0\n",
      "65                   Trier                 0                    0\n",
      "19               Flensburg                 0                    0\n",
      "37                Konstanz                 0                    0\n",
      "\n",
      "[75 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "town_ranking.sort_values(by=[\"median_train_faster\"], inplace=True, ascending=False)\n",
    "print(town_ranking)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Dataset 2: Delay causes for specific train stations\n",
    "\n",
    "In the following chapter we provide details which train stations have more problems than others to identify possible bottlenecks. \n",
    "\n",
    "### Structure of Dataset 2\n",
    "Also for Dataset 2 we first show the structure of the Dataset to get insights into the data structre. As the data pipeline for dataset 2 runs multiple times duplicates are theoretically possible, so we also again drop duplicates to be sure that no duplicates are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of        index        id message_type     from_time       to_time  \\\n",
      "0          0  r1923001            h  2.303310e+09  2.306302e+09   \n",
      "1          1  r1961074            h  2.306232e+09  2.306260e+09   \n",
      "3          3  r1982070            h  2.306232e+09  2.307122e+09   \n",
      "4          4  r1983704            h  2.306231e+09  2.306241e+09   \n",
      "7          7  r1978334            h  2.306160e+09  2.307282e+09   \n",
      "...      ...       ...          ...           ...           ...   \n",
      "42995  17327  r1985306            h  2.306241e+09  2.307012e+09   \n",
      "42996  17328  r1971077            h  2.306102e+09  2.307012e+09   \n",
      "43000  17332  r1806644            h  2.212110e+09  2.312092e+09   \n",
      "43001  17333      None         None           NaN           NaN   \n",
      "43002  17334      None         None           NaN           NaN   \n",
      "\n",
      "                                 category     timestamp  priority  \\\n",
      "0      Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0   \n",
      "1      Bauarbeiten. (Quelle: zuginfo.nrw)  2.306061e+09       2.0   \n",
      "3      Bauarbeiten. (Quelle: zuginfo.nrw)  2.306202e+09       2.0   \n",
      "4          Störung. (Quelle: zuginfo.nrw)  2.306232e+09       1.0   \n",
      "7                             Information  2.306162e+09       2.0   \n",
      "...                                   ...           ...       ...   \n",
      "42995                         Information  2.306241e+09       3.0   \n",
      "42996                         Information  2.306071e+09       1.0   \n",
      "43000                         Information  2.211232e+09       2.0   \n",
      "43001                                None           NaN       NaN   \n",
      "43002                                None           NaN       NaN   \n",
      "\n",
      "         train_station  problems_found  del  \n",
      "0           Aachen Hbf            True  NaN  \n",
      "1           Aachen Hbf            True  NaN  \n",
      "3           Aachen Hbf            True  NaN  \n",
      "4           Aachen Hbf            True  NaN  \n",
      "7           Aachen Hbf            True  NaN  \n",
      "...                ...             ...  ...  \n",
      "42995           Dessau            True  NaN  \n",
      "42996           Dessau            True  NaN  \n",
      "43000           Dessau            True  NaN  \n",
      "43001  Saarbrücken Hbf           False  NaN  \n",
      "43002     Solingen Hbf           False  NaN  \n",
      "\n",
      "[12133 rows x 11 columns]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>message_type</th>\n",
       "      <th>from_time</th>\n",
       "      <th>to_time</th>\n",
       "      <th>category</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>priority</th>\n",
       "      <th>train_station</th>\n",
       "      <th>problems_found</th>\n",
       "      <th>del</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>r1923001</td>\n",
       "      <td>h</td>\n",
       "      <td>2.303310e+09</td>\n",
       "      <td>2.306302e+09</td>\n",
       "      <td>Bauarbeiten. (Quelle: zuginfo.nrw)</td>\n",
       "      <td>2.304052e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>r1961074</td>\n",
       "      <td>h</td>\n",
       "      <td>2.306232e+09</td>\n",
       "      <td>2.306260e+09</td>\n",
       "      <td>Bauarbeiten. (Quelle: zuginfo.nrw)</td>\n",
       "      <td>2.306061e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        id message_type     from_time       to_time  \\\n",
       "0      0  r1923001            h  2.303310e+09  2.306302e+09   \n",
       "1      1  r1961074            h  2.306232e+09  2.306260e+09   \n",
       "\n",
       "                             category     timestamp  priority train_station  \\\n",
       "0  Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0    Aachen Hbf   \n",
       "1  Bauarbeiten. (Quelle: zuginfo.nrw)  2.306061e+09       2.0    Aachen Hbf   \n",
       "\n",
       "   problems_found  del  \n",
       "0            True  NaN  \n",
       "1            True  NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2_df = ds2_df.drop_duplicates(subset=[\"id\", \"message_type\", \"from_time\", \"to_time\", \"category\", \"timestamp\", \"priority\", \"train_station\", \"problems_found\", \"del\"])\n",
    "print(ds2_df.info)\n",
    "ds2_df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stations with no found problems\n",
    "\n",
    "The column problems_found indicates wether there are problems found for a station while querying the DB Api or not. \n",
    "\n",
    "We show them separatly as these are stations whose Analysis differ from the Analysis of other stations. As the query is empty every station seems to have an entry with problems in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index    id message_type  from_time  to_time category  timestamp  \\\n",
      "43001  17333  None         None        NaN      NaN     None        NaN   \n",
      "43002  17334  None         None        NaN      NaN     None        NaN   \n",
      "\n",
      "       priority    train_station  problems_found  del  \n",
      "43001       NaN  Saarbrücken Hbf           False  NaN  \n",
      "43002       NaN     Solingen Hbf           False  NaN  \n"
     ]
    }
   ],
   "source": [
    "none_delay_stations = ds2_df[ds2_df[\"problems_found\"] == False]\n",
    "print(none_delay_stations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delay causes in the dataset\n",
    "\n",
    "In the dataset is a column \"category\" for the delay causes. Not all entries seem to be real delays. Also included is a category *Information*. \n",
    "\n",
    "The following delay causes are present in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bauarbeiten. (Quelle: zuginfo.nrw)', 'Störung. (Quelle: zuginfo.nrw)', 'Information', 'Störung', None, 'Bauarbeiten', 'Information. (Quelle: zuginfo.nrw)', 'Großstörung']\n"
     ]
    }
   ],
   "source": [
    "delay_causes = list(ds2_df[\"category\"].unique())\n",
    "print(delay_causes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The german federal state Nrw seems to have its own cause type. As this information is not relevant for us in the following analysis, we remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bauarbeiten', 'Störung', 'Information', None, 'Großstörung']\n"
     ]
    }
   ],
   "source": [
    "ds2_df[\"category\"] = ds2_df[\"category\"].str.split('.').str[0]\n",
    "delay_causes = list(ds2_df[\"category\"].unique())\n",
    "print(delay_causes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute duration of an interference\n",
    "To analyze interferences better we need to calculate the duration of a delay. Therefore we subtract the from_time of the to_time and cast the timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2_df[\"from_time\"] = pd.to_datetime(ds2_df[\"from_time\"], format='%y%m%d%H%M')\n",
    "ds2_df[\"to_time\"] = pd.to_datetime(ds2_df[\"to_time\"], format='%y%m%d%H%M')\n",
    "ds2_df[\"duration\"] = ds2_df[\"to_time\"] - ds2_df[\"from_time\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delays in the operation of a specific train station\n",
    "As for connections also the information of Datasource 2 should be able to be filtered. Just select your \\<Station\\> and a \\<Delay cause\\> to make delay causes visible for a specific station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcdaf64ba0e34f8f91d2bebdc7f16ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='train_station', options=('Aachen Hbf', 'Augsburg Hbf', 'Berlin Hbf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stations = list(ds2_df[\"train_station\"].unique())\n",
    "\n",
    "@interact\n",
    "def show_train_station_information(train_station=stations, delay_cause=delay_causes):\n",
    "    station = ds2_df[(ds2_df[\"train_station\"] == train_station) & (ds2_df[\"problems_found\"] == True)]\n",
    "    if(station.empty):\n",
    "        print(\"No problems for station \", train_station, \" found!\")\n",
    "    else:\n",
    "        station = station[[\"train_station\", \"from_time\", \"to_time\", \"duration\", \"category\", \"priority\"]]\n",
    "        station = station[station[\"category\"] == delay_cause]\n",
    "        print(station)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition of the delay duration by Category and priority\n",
    "To rank stations according to their vulnerability to interferences coefficients have to be calculated for each station. As the severity of interferences differ by category and priority we group by category and priority\n",
    "\n",
    "In the following coefficients like total delay duration, average delay duration and number of delays for each station by category and priority are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_station</th>\n",
       "      <th>category</th>\n",
       "      <th>priority</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>average_duration</th>\n",
       "      <th>total_interferences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>Bauarbeiten</td>\n",
       "      <td>2.0</td>\n",
       "      <td>157 days 16:59:00</td>\n",
       "      <td>31 days 12:59:48</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>Information</td>\n",
       "      <td>2.0</td>\n",
       "      <td>389 days 07:29:00</td>\n",
       "      <td>32 days 10:37:25</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>Information</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10 days 15:45:00</td>\n",
       "      <td>5 days 07:52:30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 days 17:12:00</td>\n",
       "      <td>0 days 06:31:12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Augsburg Hbf</td>\n",
       "      <td>Bauarbeiten</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13 days 02:18:00</td>\n",
       "      <td>13 days 02:18:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Augsburg Hbf</td>\n",
       "      <td>Bauarbeiten</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4 days 14:45:00</td>\n",
       "      <td>1 days 12:55:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Augsburg Hbf</td>\n",
       "      <td>Bauarbeiten</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2 days 22:24:00</td>\n",
       "      <td>1 days 11:12:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Augsburg Hbf</td>\n",
       "      <td>Information</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0 days 14:52:00</td>\n",
       "      <td>0 days 04:57:20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Augsburg Hbf</td>\n",
       "      <td>Information</td>\n",
       "      <td>2.0</td>\n",
       "      <td>597 days 05:31:00</td>\n",
       "      <td>14 days 05:16:27.142857142</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Augsburg Hbf</td>\n",
       "      <td>Information</td>\n",
       "      <td>3.0</td>\n",
       "      <td>145 days 02:22:00</td>\n",
       "      <td>12 days 02:11:50</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_station     category  priority    total_duration  \\\n",
       "0    Aachen Hbf  Bauarbeiten       2.0 157 days 16:59:00   \n",
       "1    Aachen Hbf  Information       2.0 389 days 07:29:00   \n",
       "2    Aachen Hbf  Information       3.0  10 days 15:45:00   \n",
       "3    Aachen Hbf      Störung       1.0   2 days 17:12:00   \n",
       "4  Augsburg Hbf  Bauarbeiten       1.0  13 days 02:18:00   \n",
       "5  Augsburg Hbf  Bauarbeiten       2.0   4 days 14:45:00   \n",
       "6  Augsburg Hbf  Bauarbeiten       3.0   2 days 22:24:00   \n",
       "7  Augsburg Hbf  Information       1.0   0 days 14:52:00   \n",
       "8  Augsburg Hbf  Information       2.0 597 days 05:31:00   \n",
       "9  Augsburg Hbf  Information       3.0 145 days 02:22:00   \n",
       "\n",
       "            average_duration  total_interferences  \n",
       "0           31 days 12:59:48                    5  \n",
       "1           32 days 10:37:25                   12  \n",
       "2            5 days 07:52:30                    2  \n",
       "3            0 days 06:31:12                   10  \n",
       "4           13 days 02:18:00                    1  \n",
       "5            1 days 12:55:00                    3  \n",
       "6            1 days 11:12:00                    2  \n",
       "7            0 days 04:57:20                    3  \n",
       "8 14 days 05:16:27.142857142                   42  \n",
       "9           12 days 02:11:50                   12  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interference_metrics_of_stations = ds2_df.groupby(['train_station', 'category', 'priority']).agg({'duration': ['sum', 'mean'], 'priority': 'size'}).reset_index()\n",
    "interference_metrics_of_stations.columns = ['train_station', 'category', 'priority', 'total_duration', 'average_duration', 'total_interferences']\n",
    "interference_metrics_of_stations.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Severty of Categories and Priorities\n",
    "To finally rank stations we need to sort the different Categories and Priorities by their severnesss. It is likely that a *Großstörung (engl. major disturbance)* has more severe causes than a *Störung (engl. disturbance)*. *Bauarbeiten (engl. construction work)* is also a delay cause, but one that might lead to lesser delays in the future. *Information*s seem to be harmless. We assume the following severty order of interferences:\n",
    "\n",
    "Severty of Categories:\n",
    "1. *Großstörung*\n",
    "2. *Störung*\n",
    "3. *Bauarbeiten*\n",
    "4. *Information*\n",
    "\n",
    "Priorities show according to the DB Timetable OpenAPI document the severty of an interference. According to the OpenAPI Document priorities indicate the following severty:\n",
    "\n",
    "* *1 - High*\n",
    "* *2 - Medium*\n",
    "* *3 - Low*\n",
    "* *4 - Done*\n",
    "\n",
    "For both Categories and Priorities we should sort in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         train_station     category  priority   total_duration  \\\n",
      "199       Hannover Hbf  Großstörung       2.0  1 days 02:00:00   \n",
      "334        München Hbf  Großstörung       2.0  0 days 09:31:00   \n",
      "404     Regensburg Hbf  Großstörung       2.0  0 days 09:31:00   \n",
      "3           Aachen Hbf      Störung       1.0  2 days 17:12:00   \n",
      "10        Augsburg Hbf      Störung       1.0  9 days 12:38:00   \n",
      "14   Bergisch Gladbach      Störung       1.0  0 days 04:00:00   \n",
      "18          Berlin Hbf      Störung       1.0  0 days 02:30:00   \n",
      "23       Bielefeld Hbf      Störung       1.0 56 days 16:29:00   \n",
      "29          Bochum Hbf      Störung       1.0 11 days 09:03:00   \n",
      "35            Bonn Hbf      Störung       1.0 57 days 01:39:00   \n",
      "\n",
      "             average_duration  total_interferences  \n",
      "199           0 days 06:30:00                    4  \n",
      "334           0 days 09:31:00                    1  \n",
      "404           0 days 09:31:00                    1  \n",
      "3             0 days 06:31:12                   10  \n",
      "10            1 days 04:34:45                    8  \n",
      "14            0 days 02:00:00                    2  \n",
      "18            0 days 02:30:00                    1  \n",
      "23  5 days 03:40:49.090909090                   11  \n",
      "29  0 days 10:06:46.666666666                   27  \n",
      "35            4 days 18:08:15                   12  \n"
     ]
    }
   ],
   "source": [
    "interference_metrics_of_stations[\"category\"] = pd.Categorical(interference_metrics_of_stations[\"category\"], categories=['Großstörung', 'Störung', 'Bauarbeiten', 'Information'], ordered=True)\n",
    "interference_metrics_of_stations = interference_metrics_of_stations.sort_values(by=[\"category\", \"priority\"], ascending=[True, True])\n",
    "print(interference_metrics_of_stations.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see from this evaluation in the dataset are currently 3 events with the category *Großstörung*. What is remarkable is that München Hbf and Regensburg Hbf have for the *Großstörung* category the same total_duration. So it is very likely (also geographically) that they have the same reason.\n",
    "\n",
    "Nevertheless for München and Regensburg only one *Großstörung* interference could be counted what is not statistically significant. Hannover has more than one with an average duration of 6:30h what indicates that here might be a bigger problem at the moment. We closer look at the station of Hannover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train_station     category  priority    total_duration  \\\n",
      "199  Hannover Hbf  Großstörung       2.0   1 days 02:00:00   \n",
      "203  Hannover Hbf      Störung       1.0  11 days 12:12:00   \n",
      "204  Hannover Hbf      Störung       2.0   4 days 01:18:00   \n",
      "197  Hannover Hbf  Bauarbeiten       1.0  83 days 16:33:00   \n",
      "198  Hannover Hbf  Bauarbeiten       2.0  56 days 03:55:00   \n",
      "200  Hannover Hbf  Information       1.0  18 days 15:00:00   \n",
      "201  Hannover Hbf  Information       2.0 814 days 10:39:00   \n",
      "202  Hannover Hbf  Information       3.0 178 days 08:44:00   \n",
      "\n",
      "              average_duration  total_interferences  \n",
      "199            0 days 06:30:00                    4  \n",
      "203  0 days 10:13:46.666666666                   27  \n",
      "204  0 days 05:07:15.789473684                   19  \n",
      "197           13 days 22:45:30                    6  \n",
      "198            9 days 08:39:10                    6  \n",
      "200            2 days 01:40:00                    9  \n",
      "201 10 days 07:25:33.417721519                   79  \n",
      "202           11 days 21:22:56                   15  \n"
     ]
    }
   ],
   "source": [
    "print(interference_metrics_of_stations[interference_metrics_of_stations[\"train_station\"] == \"Hannover Hbf\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem of arguing about data of a slight time span\n",
    "As we see from the closer look, the station of Hannover has long lasting construction work. So this may be the cause for the major inference and the multiple normal interferences. It is likely that when construction work is finished, there will be less interferences in the future.\n",
    "\n",
    "As we can see, it is hard to find a reasonable ranking that withstands a closer look into the data. If the data would be grasped over a long time (like f.e. a year), long lasting construction work would still be visible in the data, but the causes of short lasting construction work would vanish and we could argue with more reason. \n",
    "\n",
    "So the first result of the analysis of dataset 2 is, we need to grasp the data over a much longer time span to get significant results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking of Stations with filtered long-lasting interferences\n",
    "Nethertheless we still like to attempt ranking the stations in Dataset 2. We saw from the previous section that under the given circumstances taking all long-lasting interferences into account would vanish our results, so we need another attempt.\n",
    "\n",
    "In the following we focus on short-lasting interferences as these are the ones that often have an immediant not planned impact. Therefore we take the dataset and focus on the events that have a max duration of 24h. We assume that this is the max *normal* interference in typical train operation.\n",
    "\n",
    "We again calculate the metrics, but filter out long-lasting interferences and the category *Großstörung* as this feature was not relevant enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_lasting_interferences = ds2_df[(ds2_df[\"duration\"] < pd.Timedelta(hours=12)) & (ds2_df[\"category\"]!=\"Großstörung\")].groupby(['train_station', 'category', 'priority']).agg({'duration': ['sum', 'mean'], 'priority': 'size'}).reset_index()\n",
    "short_lasting_interferences.columns = ['train_station', 'category', 'priority', 'total_duration', 'average_duration', 'total_interferences']\n",
    "short_lasting_interferences[\"category\"] = pd.Categorical(short_lasting_interferences[\"category\"], categories=['Großstörung', 'Störung', 'Bauarbeiten', 'Information'], ordered=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking Total_interference most meaningful criteria\n",
    "After this we again rank Dataset 2. This time we also take the average_duration and the total_interferences into account.\n",
    "\n",
    "In a first attempt we rank by total_interferences first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_station</th>\n",
       "      <th>category</th>\n",
       "      <th>priority</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>average_duration</th>\n",
       "      <th>total_interferences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Dortmund Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7 days 17:21:00</td>\n",
       "      <td>0 days 05:17:44.571428571</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Düsseldorf Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5 days 22:29:00</td>\n",
       "      <td>0 days 04:04:15.428571428</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Essen Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4 days 13:59:00</td>\n",
       "      <td>0 days 04:04:24.444444444</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Münster</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5 days 00:39:00</td>\n",
       "      <td>0 days 04:49:33.600000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Duisburg Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4 days 02:09:00</td>\n",
       "      <td>0 days 03:55:33.600000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Köln Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3 days 07:22:00</td>\n",
       "      <td>0 days 03:27:02.608695652</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Hamm</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4 days 04:30:00</td>\n",
       "      <td>0 days 04:34:05.454545454</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Hannover Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 days 16:15:00</td>\n",
       "      <td>0 days 02:55:13.636363636</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Hildesheim Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0 days 15:50:00</td>\n",
       "      <td>0 days 00:45:14.285714285</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bochum Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3 days 11:23:00</td>\n",
       "      <td>0 days 04:10:09</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train_station category  priority  total_duration  \\\n",
       "37     Dortmund Hbf  Störung       1.0 7 days 17:21:00   \n",
       "50   Düsseldorf Hbf  Störung       1.0 5 days 22:29:00   \n",
       "63        Essen Hbf  Störung       1.0 4 days 13:59:00   \n",
       "203         Münster  Störung       1.0 5 days 00:39:00   \n",
       "44     Duisburg Hbf  Störung       1.0 4 days 02:09:00   \n",
       "161        Köln Hbf  Störung       1.0 3 days 07:22:00   \n",
       "107            Hamm  Störung       1.0 4 days 04:30:00   \n",
       "118    Hannover Hbf  Störung       1.0 2 days 16:15:00   \n",
       "132  Hildesheim Hbf  Störung       1.0 0 days 15:50:00   \n",
       "14       Bochum Hbf  Störung       1.0 3 days 11:23:00   \n",
       "\n",
       "             average_duration  total_interferences  \n",
       "37  0 days 05:17:44.571428571                   35  \n",
       "50  0 days 04:04:15.428571428                   35  \n",
       "63  0 days 04:04:24.444444444                   27  \n",
       "203    0 days 04:49:33.600000                   25  \n",
       "44     0 days 03:55:33.600000                   25  \n",
       "161 0 days 03:27:02.608695652                   23  \n",
       "107 0 days 04:34:05.454545454                   22  \n",
       "118 0 days 02:55:13.636363636                   22  \n",
       "132 0 days 00:45:14.285714285                   21  \n",
       "14            0 days 04:10:09                   20  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_lasting_interferences = short_lasting_interferences.sort_values(by=[\"category\", \"total_interferences\", \"average_duration\", \"priority\"], ascending=[True, False, False, True])\n",
    "short_lasting_interferences.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This attempt was more successful then previous ones. What is noticeable is that many stations among the top 10 are in North Rhine-Westphalia.\n",
    "\n",
    "#### Ranking Average_duration as most meaningful criteria\n",
    "We secondly rank Dataset 2 by average_duration first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_station</th>\n",
       "      <th>category</th>\n",
       "      <th>priority</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>average_duration</th>\n",
       "      <th>total_interferences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Hannover Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3 days 11:19:00</td>\n",
       "      <td>0 days 04:37:43.333333333</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Kiel Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0 days 16:06:00</td>\n",
       "      <td>0 days 01:20:30</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Hamburg Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0 days 17:01:00</td>\n",
       "      <td>0 days 01:32:49.090909090</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Ulm Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0 days 16:19:00</td>\n",
       "      <td>0 days 02:19:51.428571428</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Nürnberg Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1 days 03:46:00</td>\n",
       "      <td>0 days 04:37:40</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Flensburg</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0 days 09:53:00</td>\n",
       "      <td>0 days 01:58:36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Mannheim Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0 days 20:35:00</td>\n",
       "      <td>0 days 04:07:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>München Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1 days 00:54:00</td>\n",
       "      <td>0 days 04:58:48</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Paderborn Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1 days 20:00:00</td>\n",
       "      <td>0 days 08:48:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Potsdam Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0 days 01:49:00</td>\n",
       "      <td>0 days 00:27:15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train_station category  priority  total_duration  \\\n",
       "119   Hannover Hbf  Störung       2.0 3 days 11:19:00   \n",
       "150       Kiel Hbf  Störung       2.0 0 days 16:06:00   \n",
       "104    Hamburg Hbf  Störung       2.0 0 days 17:01:00   \n",
       "264        Ulm Hbf  Störung       2.0 0 days 16:19:00   \n",
       "209   Nürnberg Hbf  Störung       2.0 1 days 03:46:00   \n",
       "71       Flensburg  Störung       2.0 0 days 09:53:00   \n",
       "189   Mannheim Hbf  Störung       2.0 0 days 20:35:00   \n",
       "199    München Hbf  Störung       2.0 1 days 00:54:00   \n",
       "224  Paderborn Hbf  Störung       2.0 1 days 20:00:00   \n",
       "228    Potsdam Hbf  Störung       2.0 0 days 01:49:00   \n",
       "\n",
       "             average_duration  total_interferences  \n",
       "119 0 days 04:37:43.333333333                   18  \n",
       "150           0 days 01:20:30                   12  \n",
       "104 0 days 01:32:49.090909090                   11  \n",
       "264 0 days 02:19:51.428571428                    7  \n",
       "209           0 days 04:37:40                    6  \n",
       "71            0 days 01:58:36                    5  \n",
       "189           0 days 04:07:00                    5  \n",
       "199           0 days 04:58:48                    5  \n",
       "224           0 days 08:48:00                    5  \n",
       "228           0 days 00:27:15                    4  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_lasting_interferences = short_lasting_interferences.sort_values(by=[\"category\", \"priority\", \"total_interferences\"], ascending=[True, False, False])\n",
    "short_lasting_interferences.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking Total-duration as most meaningful criteria\n",
    "Instead of the average_duration of an interference, we rank Dataset 2 by total_duraton first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_station</th>\n",
       "      <th>category</th>\n",
       "      <th>priority</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>average_duration</th>\n",
       "      <th>total_interferences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Dortmund Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7 days 17:21:00</td>\n",
       "      <td>0 days 05:17:44.571428571</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Düsseldorf Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5 days 22:29:00</td>\n",
       "      <td>0 days 04:04:15.428571428</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Münster</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5 days 00:39:00</td>\n",
       "      <td>0 days 04:49:33.600000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Essen Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4 days 13:59:00</td>\n",
       "      <td>0 days 04:04:24.444444444</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Hamm</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4 days 04:30:00</td>\n",
       "      <td>0 days 04:34:05.454545454</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Duisburg Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4 days 02:09:00</td>\n",
       "      <td>0 days 03:55:33.600000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hagen Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4 days 00:46:00</td>\n",
       "      <td>0 days 05:41:31.764705882</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3 days 23:23:00</td>\n",
       "      <td>0 days 07:20:13.846153846</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Mainz Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3 days 18:02:00</td>\n",
       "      <td>0 days 07:30:10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Nürnberg Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3 days 16:52:00</td>\n",
       "      <td>0 days 06:20:51.428571428</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_station category  priority  total_duration  \\\n",
       "37        Dortmund Hbf  Störung       1.0 7 days 17:21:00   \n",
       "50      Düsseldorf Hbf  Störung       1.0 5 days 22:29:00   \n",
       "203            Münster  Störung       1.0 5 days 00:39:00   \n",
       "63           Essen Hbf  Störung       1.0 4 days 13:59:00   \n",
       "107               Hamm  Störung       1.0 4 days 04:30:00   \n",
       "44        Duisburg Hbf  Störung       1.0 4 days 02:09:00   \n",
       "96           Hagen Hbf  Störung       1.0 4 days 00:46:00   \n",
       "76   Frankfurt am Main  Störung       1.0 3 days 23:23:00   \n",
       "182          Mainz Hbf  Störung       1.0 3 days 18:02:00   \n",
       "208       Nürnberg Hbf  Störung       1.0 3 days 16:52:00   \n",
       "\n",
       "             average_duration  total_interferences  \n",
       "37  0 days 05:17:44.571428571                   35  \n",
       "50  0 days 04:04:15.428571428                   35  \n",
       "203    0 days 04:49:33.600000                   25  \n",
       "63  0 days 04:04:24.444444444                   27  \n",
       "107 0 days 04:34:05.454545454                   22  \n",
       "44     0 days 03:55:33.600000                   25  \n",
       "96  0 days 05:41:31.764705882                   17  \n",
       "76  0 days 07:20:13.846153846                   13  \n",
       "182           0 days 07:30:10                   12  \n",
       "208 0 days 06:20:51.428571428                   14  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_lasting_interferences = short_lasting_interferences.sort_values(by=[\"category\", \"total_duration\", \"total_interferences\", \"priority\"], ascending=[True, False, False, True])\n",
    "short_lasting_interferences.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this last chapter we summarize our results by presenting our findings again. Furthermore we also like to indicate on which major assumptions these findings are based. Then we briefly sum up the most difficult problems tackled in the project. Finally we give an outlook how the project can be extended and how the certainty of the results can be further improved.\n",
    "\n",
    "### Findings\n",
    "\n",
    "#### Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions\n",
    "This section should briefly cover the most important assumptions that were made.\n",
    "\n",
    "#### The more delays the worse the station\n",
    "The findings in Datasource 2 require the assumption that the more delays a station has the worse the station is. This might not always be true. It is rather likely that f.e. the station Berlin Hbf has more delays than the station of Rostock. But for towns that have stations that have a comparable train frequency this assumption is likely to be true.\n",
    "\n",
    "#### One station per town\n",
    "For a town only the central train station was considered in Dataset 2, not all stations of a town.\n",
    "\n",
    "### Problems during the whole Project\n",
    "\n",
    "#### Corrupted ttl file of Datasource 1\n",
    "The most severe problem tackeled during the project was that Datasource 1 provides corrupted data. The ttl file containing the rdf graph with the connection times between the towns is syntactically false. Therefore a preprocessing was required before the graph could be parsed. The preprocessing contains replacing expressions using regexes and removing invalid signs. \n",
    "\n",
    "A relation in rdf basically consists of a triple of a *\\<subject\\>*, *\\<predicate\\>* and an *\\<object\\>* like f.e. *Erlangen* *IsConnectedTo* *Berlin*. \n",
    "\n",
    "The relation between source and destination with attributes like the driving time was also not correctly associated in rdf terms in the ttl file. For this reason attributes also had to be brought into relation with the corresponding connection by complex logical changes in the rdf file. \n",
    "\n",
    "By these changes the attributes could be brought into relation to its connection and the graph could be parsed correctly with rdflib.\n",
    "\n",
    "#### Contineous updates of Datasource 2\n",
    "Another problem was that the DB Timetable API provides potentially new informations every 30 minutes. Nethertheless some informations do not change that often (f.e. the delay cause *Bauarbeiten* are a time consuming task that lasts from days to months). Therefore one problem is the deduplication of events that were grasped multiple times. Also would it be nice to grasp the data contineously like f.e. every hour, but this what require an installation on a server that automatically calls the API as a scheduled task. This was not possible manually.\n",
    "\n",
    "#### XML representation of the data of Datasource 2\n",
    "The used endpoint of the DB Timetable API of Datasource 2 provides more information than just the delay causes in a XML representation. To retrieve only the needed data a XPATH query was used. \n",
    "\n",
    "### Outlook\n",
    "#### Contineous grasping of data from Datasource 2\n",
    "The actual dataset from Datasource 2 covers at the moment data of four different days. The data was requested about approximately the same time. An interesting enhancement would be to deploy the model to a server with much storage and call the DB Api automatically daily or hourly over a long time like f.e. a year. The current data is just a snapshot of the current state. Maybe it can be found that in the long term other stations are the ones that are the most potential for enhancements.\n",
    "\n",
    "#### Including multiple stations per town\n",
    "Some towns have multiple stations. In this report only the main train station of a town is covered. Covering other stations of towns in Dataset 2 would also provide further information.\n",
    "\n",
    "#### Comparing train connection times of Datasource 1 with real-time information of the DB Timetable API\n",
    "Furthermore the DB Timetable API provides other endpoints that provide further information of current connections. It would be interesting to compare the real average train connection times with the train connection times provided in Dataset 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Destination/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
