{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report: State of train mobility in Germany\n",
    "\n",
    "This report aims to analyze the current state of train mobility in Germany. Hereby we like to focus on the following two questions:\n",
    "\n",
    "- Where is the expansion or improvement of existing rail connections worth prioritising?\n",
    "- Where is already good train infrastructure, where should improvements be made fastly? \n",
    "\n",
    "For this purpose, connection times between different cities with different means of transport are analysed in this report. Secondly, an attempt is made to identify bootlenecks at train stations via a Deutsche Bahn timetable API.\n",
    "\n",
    "The structure of this report is as follows:\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Analysis of Dataset 1: Connection Times between German towns](#Analysis-of-dataset-1-connection-times-between-german-towns)\n",
    "3. [Analysis of Dataset 2: Delay causes for specific train stations](#Analysis-of-dataset-2-delay-causes-for-specific-train-stations)\n",
    "4. [Summary](#summary)\n",
    "\n",
    "This report is based on open data from two different datasources:\n",
    "\n",
    "### Datasource 1\n",
    "Datasource 1 holds a graph with the connection times between the biggest towns in Germany by different means of transport. \n",
    "\n",
    "The Datasource 1 data is provided under a [Creative Commons Attribution 4.0 International (CC BY 4.0)0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "Datasource information:\n",
    "- Metadata URL: https://mobilithek.info/offers/573356838940979200\n",
    "- Data URL: https://mobilithek.info/mdp-api/files/aux/573356838940979200/moin-2022-05-02.1-20220502.131229-1.ttl.bz2\n",
    "- Data Type: RDF (Star) Graph, .ttl.bz2 - Archive\n",
    "\n",
    "### Datasource 2\n",
    "The second datasource is the DB Timetable API Version 1.0.x. The timetables API can be used to query information about the current (train) traffic situation in Germany and its causes. For the report an API endpoint is called that returns all known delay causes for a train station given by an *eva number* (train station identifier). The API was called at four different days once a day.\n",
    "\n",
    "For further information see the official website [DB API Marketplace - Timetables API](https://developers.deutschebahn.com/db-api-marketplace/apis/product/timetables) There you can find also the OpenAPI-document of the DB Timetable API.\n",
    "\n",
    "The Timetables APIs data is provided under a [Creative Commons Attribution 4.0 International (CC BY 4.0)0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "Datasource information:\n",
    "- Metadata URL: https://developers.deutschebahn.com/db-api-marketplace/apis/product/timetables/api/26494#/Timetables_10213/overview\n",
    "- Data URL: https://apis.deutschebahn.com/db-api-marketplace/apis/timetables/v1/\n",
    "- Data Type: API - application/xml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This section covers all requirements for the further Analysis of both datasets like the installation of dependencies and the loading of the datasets.\n",
    "\n",
    "### Install dependencies\n",
    "Initially, install all required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.15.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly) (21.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly) (8.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->plotly) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SQLAlchemy in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.39)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy) (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat) (4.17.3)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat) (2.17.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat) (5.9.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from nbformat) (5.3.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=2.6->nbformat) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.19.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core->nbformat) (3.5.3)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core->nbformat) (306)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (8.0.6)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (8.13.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (6.23.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (8.2.0)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (25.1.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.5)\n",
      "Requirement already satisfied: stack-data in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: backcall in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (306)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\dominic\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.5.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\dominic\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install plotly\n",
    "%pip install SQLAlchemy\n",
    "%pip install nbformat\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Create a pandas dataframe using the local sqlite file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds1_df = pd.read_sql_table('connection_time_graph', 'sqlite:///project/data/train_connection_analysis.sqlite')\n",
    "ds2_df = pd.read_sql_table('timetable_for_stations', 'sqlite:///project/data/train_connection_analysis.sqlite')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Dataset 1: Connection Times between German towns\n",
    "The following chapter now covers the Analysis of Dataset 1.\n",
    "\n",
    "The question we like to answer here is which towns already have better or worser connection times to other towns in comparison the car connections times.\n",
    "\n",
    "We therefore query the graph from Dataset 1 that includes the connection times between every analyzed town with different means of transport like cars or trains."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of Dataset1\n",
    "Before diving into Analysis, we show the structure of the dataset to get a feeling about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of         index        id message_type     from_time       to_time  \\\n",
      "0           0  r1923001            h  2.303310e+09  2.306302e+09   \n",
      "1           1  r1961074            h  2.306232e+09  2.306260e+09   \n",
      "2           2  r1923001            h  2.303310e+09  2.306302e+09   \n",
      "3           3  r1982070            h  2.306232e+09  2.307122e+09   \n",
      "4           4  r1983704            h  2.306231e+09  2.306241e+09   \n",
      "...       ...       ...          ...           ...           ...   \n",
      "102431  34990  r1979052            h  2.306200e+09  2.307252e+09   \n",
      "102432  34991  r1979052            h  2.306200e+09  2.307252e+09   \n",
      "102433  34992  r1979052            h  2.306200e+09  2.307252e+09   \n",
      "102434  34993  r1979052            h  2.306200e+09  2.307252e+09   \n",
      "102435  34994  r1979052            h  2.306200e+09  2.307252e+09   \n",
      "\n",
      "                                  category     timestamp  priority  \\\n",
      "0       Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0   \n",
      "1       Bauarbeiten. (Quelle: zuginfo.nrw)  2.306061e+09       2.0   \n",
      "2       Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0   \n",
      "3       Bauarbeiten. (Quelle: zuginfo.nrw)  2.306202e+09       2.0   \n",
      "4           Störung. (Quelle: zuginfo.nrw)  2.306232e+09       1.0   \n",
      "...                                    ...           ...       ...   \n",
      "102431                         Information  2.306162e+09       2.0   \n",
      "102432                         Information  2.306162e+09       2.0   \n",
      "102433                         Information  2.306162e+09       2.0   \n",
      "102434                         Information  2.306162e+09       2.0   \n",
      "102435                         Information  2.306162e+09       2.0   \n",
      "\n",
      "       train_station  problems_found  del  \n",
      "0         Aachen Hbf            True  NaN  \n",
      "1         Aachen Hbf            True  NaN  \n",
      "2         Aachen Hbf            True  NaN  \n",
      "3         Aachen Hbf            True  NaN  \n",
      "4         Aachen Hbf            True  NaN  \n",
      "...              ...             ...  ...  \n",
      "102431        Dessau            True  NaN  \n",
      "102432        Dessau            True  NaN  \n",
      "102433        Dessau            True  NaN  \n",
      "102434        Dessau            True  NaN  \n",
      "102435        Dessau            True  NaN  \n",
      "\n",
      "[102436 rows x 11 columns]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>message_type</th>\n",
       "      <th>from_time</th>\n",
       "      <th>to_time</th>\n",
       "      <th>category</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>priority</th>\n",
       "      <th>train_station</th>\n",
       "      <th>problems_found</th>\n",
       "      <th>del</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>r1923001</td>\n",
       "      <td>h</td>\n",
       "      <td>2.303310e+09</td>\n",
       "      <td>2.306302e+09</td>\n",
       "      <td>Bauarbeiten. (Quelle: zuginfo.nrw)</td>\n",
       "      <td>2.304052e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>r1961074</td>\n",
       "      <td>h</td>\n",
       "      <td>2.306232e+09</td>\n",
       "      <td>2.306260e+09</td>\n",
       "      <td>Bauarbeiten. (Quelle: zuginfo.nrw)</td>\n",
       "      <td>2.306061e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        id message_type     from_time       to_time  \\\n",
       "0      0  r1923001            h  2.303310e+09  2.306302e+09   \n",
       "1      1  r1961074            h  2.306232e+09  2.306260e+09   \n",
       "\n",
       "                             category     timestamp  priority train_station  \\\n",
       "0  Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0    Aachen Hbf   \n",
       "1  Bauarbeiten. (Quelle: zuginfo.nrw)  2.306061e+09       2.0    Aachen Hbf   \n",
       "\n",
       "   problems_found  del  \n",
       "0            True  NaN  \n",
       "1            True  NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ds2_df.info)\n",
    "ds2_df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection Times for a specific connection\n",
    "To answer the question of the connection times about a specific connection in detail, we make details for a specific connection accessible. At first we show the information as it is in the dataset. Then we will aggregate the data by towns and calculate metrics to compare train and car connections by town.\n",
    "\n",
    "Just select your \\<Source\\> and your \\<Destination\\>. It will show the duration in minutes for a possible connection and the transportType of the connection. There are different train connections with different connection times.\n",
    "\n",
    "*Note: Sadly widgets are not working in an html/pdf report as it was not possible to export it with the functionality working (e.g. the underlaying data is not included). Therefore we also print the information for one example.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        source destination   duration transportType\n",
      "5040  Erlangen      Berlin  03h 11min         train\n",
      "5041  Erlangen      Berlin  03h 30min         train\n",
      "5042  Erlangen      Berlin  03h 10min         train\n",
      "5043  Erlangen      Berlin  04h 23min           car\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2af21157d7d49e6b864882bda1d9122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='source', options=('Aachen', 'Augsburg', 'Berlin', 'Bielefeld', 'Bo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "sources = list(ds1_df[\"source\"].unique())\n",
    "destinations = list(ds1_df[\"destination\"].unique())\n",
    "\n",
    "def extract_connection_details(source, destination):\n",
    "    connection = ds1_df[(ds1_df[\"source\"] == source) & (ds1_df[\"destination\"] == destination)]\n",
    "    connection = connection[[\"source\", \"destination\", \"duration\", \"transportType\"]]\n",
    "    connection[\"duration\"] = pd.to_datetime(connection.duration, unit='m').dt.strftime('%Hh %Mmin')\n",
    "    print(connection)\n",
    "\n",
    "# only for report:\n",
    "extract_connection_details('Erlangen', 'Berlin')\n",
    "\n",
    "@interact\n",
    "def show_basic_connection_information(source=sources,\n",
    "                                destination=destinations):\n",
    "    extract_connection_details(source, destination)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate connection times per connection into a single row and calculate mean/min train duration\n",
    "\n",
    "To answer the question where are already good train connections, we need to compare the connection times by car with them by train. Therefore we pick the fastest train connection and the median and compare connection times to the ones by car. We store the information for a specific connection in a single row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   source destination  median_train_duration  min_train_duration  car_duration\n",
      "0  Aachen    Augsburg                  314.0                 302           318\n",
      "1  Aachen      Berlin                  356.0                 351           352\n"
     ]
    }
   ],
   "source": [
    "# Select the train connections, group the trains connections by 'source' and 'destination' and calculate the median and minimum duration\n",
    "train_df = ds1_df[ds1_df['transportType'] == 'train']\n",
    "train_grouped = train_df.groupby(['source', 'destination'])['duration'].agg(['median', 'min']).reset_index()\n",
    "\n",
    "# Filter the DataFrame for 'car' durations\n",
    "car_df = ds1_df[ds1_df['transportType'] == 'car']\n",
    "car_df = car_df[[\"source\", \"destination\", \"duration\"]]\n",
    "#print(car_df)\n",
    "\n",
    "# Merge the train_df and car_df on 'source' and 'destination'\n",
    "connection_times_df = pd.merge(train_grouped, car_df, on=['source', 'destination'], how='left')\n",
    "\n",
    "# Rename the columns\n",
    "connection_times_df.rename(columns={'median': 'median_train_duration', 'min': 'min_train_duration', 'duration': 'car_duration'}, inplace=True)\n",
    "\n",
    "print(connection_times_df.head(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare train connection times with car connection times\n",
    "To answer the question where a train connection is already better than a car connection, calculate the difference of the connection times. \n",
    "\n",
    "* Positive values x mean that a train connection is faster by x minutes than the car connection between a source and a destination.\n",
    "* Negative values x mean that a train connection is slower by x minutes than the car connection between a source and a destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   source destination  median_train_duration  min_train_duration  \\\n",
      "0  Aachen    Augsburg                  314.0                 302   \n",
      "1  Aachen      Berlin                  356.0                 351   \n",
      "\n",
      "   car_duration  diff_car_median_train_duration  diff_car_min_train_duration  \n",
      "0           318                             4.0                           16  \n",
      "1           352                            -4.0                            1  \n"
     ]
    }
   ],
   "source": [
    "connection_times_df[\"diff_car_median_train_duration\"] = connection_times_df[\"car_duration\"] - connection_times_df[\"median_train_duration\"]\n",
    "connection_times_df[\"diff_car_min_train_duration\"] = connection_times_df[\"car_duration\"] - connection_times_df[\"min_train_duration\"]\n",
    "\n",
    "print(connection_times_df.head(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show metrics for a specific connection\n",
    "\n",
    "Now we can show the calculated metrics for a specific connection and show which transportation type is faster for a specific connection between two towns.\n",
    "\n",
    "*As widget are not working in an html/pdf report, we again print the information for one example.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        source destination  median_train_duration  min_train_duration  \\\n",
      "1260  Erlangen      Berlin                  191.0                 190   \n",
      "\n",
      "      car_duration  diff_car_median_train_duration  \\\n",
      "1260           263                            72.0   \n",
      "\n",
      "      diff_car_min_train_duration  \n",
      "1260                           73  \n",
      "\n",
      "The fastest train connection from Erlangen to Berlin is 73 minutes faster than the car connection.\n",
      "\n",
      "The median train connection from Erlangen to Berlin is 72.0 minutes faster than the car connection.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e806c12b235c4fb1a3d9c50776a5249b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='source', options=('Aachen', 'Augsburg', 'Berlin', 'Bielefeld', 'Bo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remember, we calculated the sources and destinations list for the dropbox earlier\n",
    "\n",
    "def show_metrics_for_a_connection(source, destination):\n",
    "    connection = connection_times_df[(connection_times_df[\"source\"] == source) & (connection_times_df[\"destination\"] == destination)]\n",
    "    print(connection)\n",
    "    diff_car_min_train_duration = connection[\"diff_car_min_train_duration\"].values[0]\n",
    "    diff_car_median_train_duration = connection[\"diff_car_median_train_duration\"].values[0]\n",
    "    \n",
    "    if diff_car_min_train_duration > 0:\n",
    "        print(f\"\\nThe fastest train connection from {source} to {destination} is {diff_car_min_train_duration} minutes faster than the car connection.\")\n",
    "    else:\n",
    "        print(f\"\\nThe fastest train connection from {source} to {destination} is {diff_car_min_train_duration} minutes slower than the car connection.\")\n",
    "    \n",
    "    if diff_car_median_train_duration > 0:\n",
    "        print(f\"\\nThe median train connection from {source} to {destination} is {diff_car_median_train_duration} minutes faster than the car connection.\")\n",
    "    else:\n",
    "        print(f\"\\nThe median train connection from {source} to {destination} is {diff_car_median_train_duration} minutes slower than the car connection.\")\n",
    "\n",
    "\n",
    "# only for report:\n",
    "show_metrics_for_a_connection('Erlangen', 'Berlin')\n",
    "\n",
    "@interact\n",
    "def show_metrics_for_a_connection_widget(source=sources,\n",
    "                                destination=destinations):\n",
    "    show_metrics_for_a_connection(source, destination)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking of towns with good train connections\n",
    "\n",
    "To show which towns already have good train connections we now calculate for all outgoing connections from a town if the car or the train is faster to all destinations and count the results. We then create a ranking to highlight towns that are better accessible by car and towns that are better accessible by train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_train_faster = connection_times_df.groupby(\"source\")[\"diff_car_min_train_duration\"].apply(lambda diff_car_min_train_duration: (diff_car_min_train_duration > 0).sum()).reset_index(name=\"min_train_faster\")\n",
    "median_train_faster = connection_times_df.groupby(\"source\")[\"diff_car_median_train_duration\"].apply(lambda diff_car_min_train_duration: (diff_car_min_train_duration > 0).sum()).reset_index(name=\"median_train_faster\")\n",
    "\n",
    "town_ranking = pd.merge(min_train_faster, median_train_faster, on=\"source\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Towns sorted by the number of outgoing connections where the **fastest** train connection is faster than the car connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    source  min_train_faster  median_train_faster\n",
      "2                   Berlin                57                   26\n",
      "44                Mannheim                47                   38\n",
      "64               Stuttgart                43                   24\n",
      "1                 Augsburg                42                   18\n",
      "33               Karlsruhe                40                   11\n",
      "..                     ...               ...                  ...\n",
      "35                    Kiel                 1                    0\n",
      "68  Villingen-Schwenningen                 0                    0\n",
      "65                   Trier                 0                    0\n",
      "19               Flensburg                 0                    0\n",
      "37                Konstanz                 0                    0\n",
      "\n",
      "[75 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "town_ranking.sort_values(by=[\"min_train_faster\"], inplace=True, ascending=False)\n",
    "print(town_ranking)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Towns sorted by the number of outgoing connections where the **median** train connection is faster than the car connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    source  min_train_faster  median_train_faster\n",
      "44                Mannheim                47                   38\n",
      "2                   Berlin                57                   26\n",
      "64               Stuttgart                43                   24\n",
      "15                Duisburg                32                   21\n",
      "30              Ingolstadt                35                   20\n",
      "..                     ...               ...                  ...\n",
      "35                    Kiel                 1                    0\n",
      "68  Villingen-Schwenningen                 0                    0\n",
      "65                   Trier                 0                    0\n",
      "19               Flensburg                 0                    0\n",
      "37                Konstanz                 0                    0\n",
      "\n",
      "[75 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "town_ranking.sort_values(by=[\"median_train_faster\"], inplace=True, ascending=False)\n",
    "print(town_ranking)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Dataset 2: Delay causes for specific train stations\n",
    "\n",
    "In the following chapter we provide details which train stations have more problems than others to identify possible bottlenecks. \n",
    "\n",
    "### Structure of Dataset 2\n",
    "Also for Dataset 2 we first show the structure of the Dataset to get insights into the data structre. As the data pipeline for dataset 2 runs multiple times duplicates are theoretically possible, so we also again drop duplicates to be sure that no duplicates are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of         index           id message_type     from_time       to_time  \\\n",
      "0           0     r1923001            h  2.303310e+09  2.306302e+09   \n",
      "1           1     r1961074            h  2.306232e+09  2.306260e+09   \n",
      "3           3     r1982070            h  2.306232e+09  2.307122e+09   \n",
      "4           4     r1983704            h  2.306231e+09  2.306241e+09   \n",
      "7           7     r1978334            h  2.306160e+09  2.307282e+09   \n",
      "...       ...          ...          ...           ...           ...   \n",
      "102426  34985  r3585038122            c           NaN           NaN   \n",
      "102427  34986  r3585038123            c           NaN           NaN   \n",
      "102428  34987  r3585038037            c           NaN           NaN   \n",
      "102429  34988  r3585037787            c           NaN           NaN   \n",
      "102430  34989     r1979052            h  2.306200e+09  2.307252e+09   \n",
      "\n",
      "                                  category     timestamp  priority  \\\n",
      "0       Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0   \n",
      "1       Bauarbeiten. (Quelle: zuginfo.nrw)  2.306061e+09       2.0   \n",
      "3       Bauarbeiten. (Quelle: zuginfo.nrw)  2.306202e+09       2.0   \n",
      "4           Störung. (Quelle: zuginfo.nrw)  2.306232e+09       1.0   \n",
      "7                              Information  2.306162e+09       2.0   \n",
      "...                                    ...           ...       ...   \n",
      "102426                                None  2.306272e+09       NaN   \n",
      "102427                                None  2.306272e+09       NaN   \n",
      "102428                                None  2.306272e+09       NaN   \n",
      "102429                                None  2.306272e+09       NaN   \n",
      "102430                         Information  2.306162e+09       2.0   \n",
      "\n",
      "       train_station  problems_found  del  \n",
      "0         Aachen Hbf            True  NaN  \n",
      "1         Aachen Hbf            True  NaN  \n",
      "3         Aachen Hbf            True  NaN  \n",
      "4         Aachen Hbf            True  NaN  \n",
      "7         Aachen Hbf            True  NaN  \n",
      "...              ...             ...  ...  \n",
      "102426        Dessau            True  NaN  \n",
      "102427        Dessau            True  NaN  \n",
      "102428        Dessau            True  NaN  \n",
      "102429        Dessau            True  NaN  \n",
      "102430        Dessau            True  NaN  \n",
      "\n",
      "[21584 rows x 11 columns]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>message_type</th>\n",
       "      <th>from_time</th>\n",
       "      <th>to_time</th>\n",
       "      <th>category</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>priority</th>\n",
       "      <th>train_station</th>\n",
       "      <th>problems_found</th>\n",
       "      <th>del</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>r1923001</td>\n",
       "      <td>h</td>\n",
       "      <td>2.303310e+09</td>\n",
       "      <td>2.306302e+09</td>\n",
       "      <td>Bauarbeiten. (Quelle: zuginfo.nrw)</td>\n",
       "      <td>2.304052e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>r1961074</td>\n",
       "      <td>h</td>\n",
       "      <td>2.306232e+09</td>\n",
       "      <td>2.306260e+09</td>\n",
       "      <td>Bauarbeiten. (Quelle: zuginfo.nrw)</td>\n",
       "      <td>2.306061e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        id message_type     from_time       to_time  \\\n",
       "0      0  r1923001            h  2.303310e+09  2.306302e+09   \n",
       "1      1  r1961074            h  2.306232e+09  2.306260e+09   \n",
       "\n",
       "                             category     timestamp  priority train_station  \\\n",
       "0  Bauarbeiten. (Quelle: zuginfo.nrw)  2.304052e+09       2.0    Aachen Hbf   \n",
       "1  Bauarbeiten. (Quelle: zuginfo.nrw)  2.306061e+09       2.0    Aachen Hbf   \n",
       "\n",
       "   problems_found  del  \n",
       "0            True  NaN  \n",
       "1            True  NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2_df = ds2_df.drop_duplicates(subset=[\"id\", \"message_type\", \"from_time\", \"to_time\", \"category\", \"timestamp\", \"priority\", \"train_station\", \"problems_found\", \"del\"])\n",
    "print(ds2_df.info)\n",
    "ds2_df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stations with no found problems\n",
    "\n",
    "The column problems_found indicates wether there are problems found for a station while querying the DB Api or not. \n",
    "\n",
    "We show them separatly as these are stations whose Analysis differ from the Analysis of other stations. As the query is empty every station seems to have an entry with problems in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index    id message_type  from_time  to_time category  timestamp  \\\n",
      "43001  17333  None         None        NaN      NaN     None        NaN   \n",
      "43002  17334  None         None        NaN      NaN     None        NaN   \n",
      "\n",
      "       priority    train_station  problems_found  del  \n",
      "43001       NaN  Saarbrücken Hbf           False  NaN  \n",
      "43002       NaN     Solingen Hbf           False  NaN  \n"
     ]
    }
   ],
   "source": [
    "none_delay_stations = ds2_df[ds2_df[\"problems_found\"] == False]\n",
    "print(none_delay_stations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delay causes in the dataset\n",
    "\n",
    "In the dataset is a column \"category\" for the delay causes. Not all entries seem to be real delays. Also included is a category *Information*. \n",
    "\n",
    "The following delay causes are present in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bauarbeiten. (Quelle: zuginfo.nrw)', 'Störung. (Quelle: zuginfo.nrw)', 'Information', 'Störung', None, 'Bauarbeiten', 'Information. (Quelle: zuginfo.nrw)', 'Großstörung']\n"
     ]
    }
   ],
   "source": [
    "delay_causes = list(ds2_df[\"category\"].unique())\n",
    "print(delay_causes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The german federal state Nrw seems to have its own cause type. As this information is not relevant for us in the following analysis, we remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bauarbeiten', 'Störung', 'Information', None, 'Großstörung']\n"
     ]
    }
   ],
   "source": [
    "ds2_df[\"category\"] = ds2_df[\"category\"].str.split('.').str[0]\n",
    "delay_causes = list(ds2_df[\"category\"].unique())\n",
    "print(delay_causes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute duration of an interference\n",
    "To analyze interferences better we need to calculate the duration of a delay. Therefore we subtract the from_time of the to_time and cast the timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2_df[\"from_time\"] = pd.to_datetime(ds2_df[\"from_time\"], format='%y%m%d%H%M')\n",
    "ds2_df[\"to_time\"] = pd.to_datetime(ds2_df[\"to_time\"], format='%y%m%d%H%M')\n",
    "ds2_df[\"duration\"] = ds2_df[\"to_time\"] - ds2_df[\"from_time\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delays in the operation of a specific train station\n",
    "As for connections also the information of Datasource 2 should be able to be filtered. Just select your \\<Station\\> and a \\<Delay cause\\> to make delay causes visible for a specific station.\n",
    "\n",
    "*As widget are not working in an html/pdf report, we again print the information for one example.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train_station           from_time             to_time        duration  \\\n",
      "29318      Erlangen 2023-06-25 23:08:00 2023-06-26 01:55:00 0 days 02:47:00   \n",
      "49045      Erlangen 2023-06-26 23:08:00 2023-06-27 01:55:00 0 days 02:47:00   \n",
      "\n",
      "          category  priority  \n",
      "29318  Bauarbeiten       2.0  \n",
      "49045  Bauarbeiten       2.0  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796d2b521ec84dd792eb447a0f6bfe46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='train_station', options=('Aachen Hbf', 'Augsburg Hbf', 'Berlin Hbf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stations = list(ds2_df[\"train_station\"].unique())\n",
    "\n",
    "def show_train_station_information(train_station, delay_cause):\n",
    "    station = ds2_df[(ds2_df[\"train_station\"] == train_station) & (ds2_df[\"problems_found\"] == True)]\n",
    "    if(station.empty):\n",
    "        print(\"No problems for station \", train_station, \" found!\")\n",
    "    else:\n",
    "        station = station[[\"train_station\", \"from_time\", \"to_time\", \"duration\", \"category\", \"priority\"]]\n",
    "        station = station[station[\"category\"] == delay_cause]\n",
    "        print(station)\n",
    "\n",
    "show_train_station_information(\"Erlangen\", \"Bauarbeiten\")\n",
    "\n",
    "@interact\n",
    "def show_train_station_information_widget(train_station=stations, delay_cause=delay_causes):\n",
    "    show_train_station_information(train_station, delay_cause)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition of the delay duration by Category and priority\n",
    "To rank stations according to their vulnerability to interferences coefficients have to be calculated for each station. As the severity of interferences differ by category and priority we group by category and priority\n",
    "\n",
    "In the following coefficients like total delay duration, average delay duration and number of delays for each station by category and priority are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_station</th>\n",
       "      <th>category</th>\n",
       "      <th>priority</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>average_duration</th>\n",
       "      <th>total_interferences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>Bauarbeiten</td>\n",
       "      <td>2.0</td>\n",
       "      <td>244 days 21:29:00</td>\n",
       "      <td>40 days 19:34:50</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>Information</td>\n",
       "      <td>2.0</td>\n",
       "      <td>950 days 20:27:00</td>\n",
       "      <td>31 days 16:40:54</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>Information</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39 days 03:11:00</td>\n",
       "      <td>4 days 08:21:13.333333333</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aachen Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6 days 03:00:00</td>\n",
       "      <td>0 days 05:52:48</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Augsburg Hbf</td>\n",
       "      <td>Bauarbeiten</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13 days 02:18:00</td>\n",
       "      <td>13 days 02:18:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Augsburg Hbf</td>\n",
       "      <td>Bauarbeiten</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4 days 15:38:00</td>\n",
       "      <td>1 days 03:54:30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Augsburg Hbf</td>\n",
       "      <td>Bauarbeiten</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2 days 22:24:00</td>\n",
       "      <td>1 days 11:12:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Augsburg Hbf</td>\n",
       "      <td>Information</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1 days 15:35:00</td>\n",
       "      <td>0 days 02:19:42.352941176</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Augsburg Hbf</td>\n",
       "      <td>Information</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1277 days 03:14:00</td>\n",
       "      <td>13 days 00:46:03.673469387</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Augsburg Hbf</td>\n",
       "      <td>Information</td>\n",
       "      <td>3.0</td>\n",
       "      <td>162 days 17:45:00</td>\n",
       "      <td>7 days 09:32:02.727272727</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_station     category  priority     total_duration  \\\n",
       "0    Aachen Hbf  Bauarbeiten       2.0  244 days 21:29:00   \n",
       "1    Aachen Hbf  Information       2.0  950 days 20:27:00   \n",
       "2    Aachen Hbf  Information       3.0   39 days 03:11:00   \n",
       "3    Aachen Hbf      Störung       1.0    6 days 03:00:00   \n",
       "4  Augsburg Hbf  Bauarbeiten       1.0   13 days 02:18:00   \n",
       "5  Augsburg Hbf  Bauarbeiten       2.0    4 days 15:38:00   \n",
       "6  Augsburg Hbf  Bauarbeiten       3.0    2 days 22:24:00   \n",
       "7  Augsburg Hbf  Information       1.0    1 days 15:35:00   \n",
       "8  Augsburg Hbf  Information       2.0 1277 days 03:14:00   \n",
       "9  Augsburg Hbf  Information       3.0  162 days 17:45:00   \n",
       "\n",
       "            average_duration  total_interferences  \n",
       "0           40 days 19:34:50                    6  \n",
       "1           31 days 16:40:54                   30  \n",
       "2  4 days 08:21:13.333333333                    9  \n",
       "3            0 days 05:52:48                   25  \n",
       "4           13 days 02:18:00                    1  \n",
       "5            1 days 03:54:30                    4  \n",
       "6            1 days 11:12:00                    2  \n",
       "7  0 days 02:19:42.352941176                   17  \n",
       "8 13 days 00:46:03.673469387                   98  \n",
       "9  7 days 09:32:02.727272727                   22  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interference_metrics_of_stations = ds2_df.groupby(['train_station', 'category', 'priority']).agg({'duration': ['sum', 'mean'], 'priority': 'size'}).reset_index()\n",
    "interference_metrics_of_stations.columns = ['train_station', 'category', 'priority', 'total_duration', 'average_duration', 'total_interferences']\n",
    "interference_metrics_of_stations.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Severty of Categories and Priorities\n",
    "To finally rank stations we need to sort the different Categories and Priorities by their severnesss. It is likely that a *Großstörung (engl. major disturbance)* has more severe causes than a *Störung (engl. disturbance)*. *Bauarbeiten (engl. construction work)* is also a delay cause, but one that might lead to lesser delays in the future. *Information*s seem to be harmless. We assume the following severty order of interferences:\n",
    "\n",
    "Severty of Categories:\n",
    "1. *Großstörung*\n",
    "2. *Störung*\n",
    "3. *Bauarbeiten*\n",
    "4. *Information*\n",
    "\n",
    "Priorities show according to the DB Timetable OpenAPI document the severty of an interference. According to the OpenAPI Document priorities indicate the following severty:\n",
    "\n",
    "* *1 - High*\n",
    "* *2 - Medium*\n",
    "* *3 - Low*\n",
    "* *4 - Done*\n",
    "\n",
    "For both Categories and Priorities we should sort in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         train_station     category  priority   total_duration  \\\n",
      "217       Hannover Hbf  Großstörung       2.0  1 days 08:00:00   \n",
      "239     Hildesheim Hbf  Großstörung       2.0  0 days 06:00:00   \n",
      "360             Minden  Großstörung       2.0  0 days 06:00:00   \n",
      "381        München Hbf  Großstörung       2.0  0 days 09:31:00   \n",
      "430      Paderborn Hbf  Großstörung       2.0  0 days 06:00:00   \n",
      "455     Regensburg Hbf  Großstörung       2.0  0 days 09:31:00   \n",
      "3           Aachen Hbf      Störung       1.0  6 days 03:00:00   \n",
      "10        Augsburg Hbf      Störung       1.0 10 days 13:44:00   \n",
      "14   Bergisch Gladbach      Störung       1.0  1 days 20:21:00   \n",
      "18          Berlin Hbf      Störung       1.0  0 days 17:36:00   \n",
      "\n",
      "             average_duration  total_interferences  \n",
      "217           0 days 06:24:00                    5  \n",
      "239           0 days 06:00:00                    1  \n",
      "360           0 days 06:00:00                    1  \n",
      "381           0 days 09:31:00                    1  \n",
      "430           0 days 06:00:00                    1  \n",
      "455           0 days 09:31:00                    1  \n",
      "3             0 days 05:52:48                   25  \n",
      "10  0 days 19:31:04.615384615                   13  \n",
      "14            0 days 07:23:30                    6  \n",
      "18            0 days 04:24:00                    4  \n"
     ]
    }
   ],
   "source": [
    "interference_metrics_of_stations[\"category\"] = pd.Categorical(interference_metrics_of_stations[\"category\"], categories=['Großstörung', 'Störung', 'Bauarbeiten', 'Information'], ordered=True)\n",
    "interference_metrics_of_stations = interference_metrics_of_stations.sort_values(by=[\"category\", \"priority\"], ascending=[True, True])\n",
    "print(interference_metrics_of_stations.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see from this evaluation in the dataset are currently 3 events with the category *Großstörung*. What is remarkable is that München Hbf and Regensburg Hbf have for the *Großstörung* category the same total_duration. So it is very likely (also geographically) that they have the same reason.\n",
    "\n",
    "Nevertheless for München and Regensburg only one *Großstörung* interference could be counted what is not statistically significant. Hannover has more than one with an average duration of 6:30h what indicates that here might be a bigger problem at the moment. We closer look at the station of Hannover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train_station     category  priority     total_duration  \\\n",
      "217  Hannover Hbf  Großstörung       2.0    1 days 08:00:00   \n",
      "221  Hannover Hbf      Störung       1.0   12 days 12:17:00   \n",
      "222  Hannover Hbf      Störung       2.0   23 days 00:27:00   \n",
      "214  Hannover Hbf  Bauarbeiten       1.0   83 days 16:33:00   \n",
      "215  Hannover Hbf  Bauarbeiten       2.0   62 days 04:45:00   \n",
      "216  Hannover Hbf  Bauarbeiten       3.0    8 days 08:00:00   \n",
      "218  Hannover Hbf  Information       1.0   20 days 01:35:00   \n",
      "219  Hannover Hbf  Information       2.0 1640 days 16:14:00   \n",
      "220  Hannover Hbf  Information       3.0  198 days 15:36:00   \n",
      "\n",
      "             average_duration  total_interferences  \n",
      "217           0 days 06:24:00                    5  \n",
      "221    0 days 09:23:01.875000                   32  \n",
      "222    0 days 22:05:52.800000                   25  \n",
      "214          13 days 22:45:30                    6  \n",
      "215           6 days 05:16:30                   10  \n",
      "216           8 days 08:00:00                    1  \n",
      "218 0 days 22:55:57.142857142                   21  \n",
      "219 7 days 22:13:24.057971014                  207  \n",
      "220 7 days 02:16:17.142857142                   28  \n"
     ]
    }
   ],
   "source": [
    "print(interference_metrics_of_stations[interference_metrics_of_stations[\"train_station\"] == \"Hannover Hbf\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem of arguing about data of a slight time span\n",
    "As we see from the closer look, the station of Hannover has long lasting construction work. So this may be the cause for the major inference and the multiple normal interferences. It is likely that when construction work is finished, there will be less interferences in the future.\n",
    "\n",
    "As we can see, it is hard to find a reasonable ranking that withstands a closer look into the data. If the data would be grasped over a long time (like f.e. a year), long lasting construction work would still be visible in the data, but the causes of short lasting construction work would vanish and we could argue with more reason. \n",
    "\n",
    "So the first result of the analysis of dataset 2 is, we need to grasp the data over a much longer time span to get significant results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking of Stations with filtered long-lasting interferences\n",
    "Nethertheless we still like to attempt ranking the stations in Dataset 2. We saw from the previous section that under the given circumstances taking all long-lasting interferences into account would vanish our results, so we need another attempt.\n",
    "\n",
    "In the following we focus on short-lasting interferences as these are the ones that often have an immediant not planned impact. Therefore we take the dataset and focus on the events that have a max duration of 24h. We assume that this is the max *normal* interference in typical train operation.\n",
    "\n",
    "We again calculate the metrics, but filter out long-lasting interferences and the category *Großstörung* as this feature was not relevant enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_lasting_interferences = ds2_df[(ds2_df[\"duration\"] < pd.Timedelta(hours=12)) & (ds2_df[\"category\"]!=\"Großstörung\")].groupby(['train_station', 'category', 'priority']).agg({'duration': ['sum', 'mean'], 'priority': 'size'}).reset_index()\n",
    "short_lasting_interferences.columns = ['train_station', 'category', 'priority', 'total_duration', 'average_duration', 'total_interferences']\n",
    "short_lasting_interferences[\"category\"] = pd.Categorical(short_lasting_interferences[\"category\"], categories=['Großstörung', 'Störung', 'Bauarbeiten', 'Information'], ordered=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking Total_interference most meaningful criteria\n",
    "After this we again rank Dataset 2. This time we also take the average_duration and the total_interferences into account.\n",
    "\n",
    "In a first attempt we rank by total_interferences first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_station</th>\n",
       "      <th>category</th>\n",
       "      <th>priority</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>average_duration</th>\n",
       "      <th>total_interferences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Düsseldorf Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13 days 09:04:00</td>\n",
       "      <td>0 days 04:20:19.459459459</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Dortmund Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14 days 18:37:00</td>\n",
       "      <td>0 days 04:55:30.833333333</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Köln Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11 days 15:01:00</td>\n",
       "      <td>0 days 04:21:34.687500</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Essen Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10 days 22:41:00</td>\n",
       "      <td>0 days 04:10:10.476190476</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Duisburg Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11 days 04:33:00</td>\n",
       "      <td>0 days 04:19:53.225806451</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Münster</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11 days 13:30:00</td>\n",
       "      <td>0 days 04:52:06.315789473</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Hamm</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10 days 09:09:00</td>\n",
       "      <td>0 days 04:42:03.396226415</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bochum Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9 days 01:11:00</td>\n",
       "      <td>0 days 04:20:37.200000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Mülheim an der Ruhr</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7 days 11:02:00</td>\n",
       "      <td>0 days 04:04:08.181818181</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Neuss Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7 days 03:10:00</td>\n",
       "      <td>0 days 04:37:34.054054054</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train_station category  priority   total_duration  \\\n",
       "74        Düsseldorf Hbf  Störung       1.0 13 days 09:04:00   \n",
       "54          Dortmund Hbf  Störung       1.0 14 days 18:37:00   \n",
       "223             Köln Hbf  Störung       1.0 11 days 15:01:00   \n",
       "92             Essen Hbf  Störung       1.0 10 days 22:41:00   \n",
       "65          Duisburg Hbf  Störung       1.0 11 days 04:33:00   \n",
       "286              Münster  Störung       1.0 11 days 13:30:00   \n",
       "153                 Hamm  Störung       1.0 10 days 09:09:00   \n",
       "22            Bochum Hbf  Störung       1.0  9 days 01:11:00   \n",
       "275  Mülheim an der Ruhr  Störung       1.0  7 days 11:02:00   \n",
       "289            Neuss Hbf  Störung       1.0  7 days 03:10:00   \n",
       "\n",
       "             average_duration  total_interferences  \n",
       "74  0 days 04:20:19.459459459                   74  \n",
       "54  0 days 04:55:30.833333333                   72  \n",
       "223    0 days 04:21:34.687500                   64  \n",
       "92  0 days 04:10:10.476190476                   63  \n",
       "65  0 days 04:19:53.225806451                   62  \n",
       "286 0 days 04:52:06.315789473                   57  \n",
       "153 0 days 04:42:03.396226415                   53  \n",
       "22     0 days 04:20:37.200000                   50  \n",
       "275 0 days 04:04:08.181818181                   44  \n",
       "289 0 days 04:37:34.054054054                   37  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_lasting_interferences = short_lasting_interferences.sort_values(by=[\"category\", \"total_interferences\", \"average_duration\", \"priority\"], ascending=[True, False, False, True])\n",
    "short_lasting_interferences.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This attempt was more successful then previous ones. What is noticeable is that many stations among the top 10 are in North Rhine-Westphalia.\n",
    "\n",
    "#### Ranking Average_duration as most meaningful criteria\n",
    "We secondly rank Dataset 2 by average_duration first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_station</th>\n",
       "      <th>category</th>\n",
       "      <th>priority</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>average_duration</th>\n",
       "      <th>total_interferences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Hannover Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4 days 07:17:00</td>\n",
       "      <td>0 days 04:29:26.086956521</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Kiel Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1 days 10:43:00</td>\n",
       "      <td>0 days 01:44:09</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Hamburg Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1 days 13:17:00</td>\n",
       "      <td>0 days 02:19:48.750000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Ulm Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1 days 07:24:00</td>\n",
       "      <td>0 days 02:51:16.363636363</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Nürnberg Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1 days 19:56:00</td>\n",
       "      <td>0 days 04:52:53.333333333</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Mannheim Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1 days 17:49:00</td>\n",
       "      <td>0 days 04:38:46.666666666</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Hildesheim Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0 days 13:52:00</td>\n",
       "      <td>0 days 01:32:26.666666666</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>München Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1 days 13:05:00</td>\n",
       "      <td>0 days 04:38:07.500000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1 days 05:43:00</td>\n",
       "      <td>0 days 04:14:42.857142857</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Heidelberg Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1 days 03:50:00</td>\n",
       "      <td>0 days 03:58:34.285714285</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_station category  priority  total_duration  \\\n",
       "168       Hannover Hbf  Störung       2.0 4 days 07:17:00   \n",
       "209           Kiel Hbf  Störung       2.0 1 days 10:43:00   \n",
       "149        Hamburg Hbf  Störung       2.0 1 days 13:17:00   \n",
       "372            Ulm Hbf  Störung       2.0 1 days 07:24:00   \n",
       "296       Nürnberg Hbf  Störung       2.0 1 days 19:56:00   \n",
       "263       Mannheim Hbf  Störung       2.0 1 days 17:49:00   \n",
       "183     Hildesheim Hbf  Störung       2.0 0 days 13:52:00   \n",
       "282        München Hbf  Störung       2.0 1 days 13:05:00   \n",
       "108  Frankfurt am Main  Störung       2.0 1 days 05:43:00   \n",
       "174     Heidelberg Hbf  Störung       2.0 1 days 03:50:00   \n",
       "\n",
       "             average_duration  total_interferences  \n",
       "168 0 days 04:29:26.086956521                   23  \n",
       "209           0 days 01:44:09                   20  \n",
       "149    0 days 02:19:48.750000                   16  \n",
       "372 0 days 02:51:16.363636363                   11  \n",
       "296 0 days 04:52:53.333333333                    9  \n",
       "263 0 days 04:38:46.666666666                    9  \n",
       "183 0 days 01:32:26.666666666                    9  \n",
       "282    0 days 04:38:07.500000                    8  \n",
       "108 0 days 04:14:42.857142857                    7  \n",
       "174 0 days 03:58:34.285714285                    7  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_lasting_interferences = short_lasting_interferences.sort_values(by=[\"category\", \"priority\", \"total_interferences\"], ascending=[True, False, False])\n",
    "short_lasting_interferences.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking Total-duration as most meaningful criteria\n",
    "Instead of the average_duration of an interference, we rank Dataset 2 by total_duraton first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_station</th>\n",
       "      <th>category</th>\n",
       "      <th>priority</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>average_duration</th>\n",
       "      <th>total_interferences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Dortmund Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14 days 18:37:00</td>\n",
       "      <td>0 days 04:55:30.833333333</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Düsseldorf Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13 days 09:04:00</td>\n",
       "      <td>0 days 04:20:19.459459459</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Köln Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11 days 15:01:00</td>\n",
       "      <td>0 days 04:21:34.687500</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Münster</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11 days 13:30:00</td>\n",
       "      <td>0 days 04:52:06.315789473</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Duisburg Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11 days 04:33:00</td>\n",
       "      <td>0 days 04:19:53.225806451</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Essen Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10 days 22:41:00</td>\n",
       "      <td>0 days 04:10:10.476190476</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Hamm</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10 days 09:09:00</td>\n",
       "      <td>0 days 04:42:03.396226415</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bochum Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9 days 01:11:00</td>\n",
       "      <td>0 days 04:20:37.200000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Mülheim an der Ruhr</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7 days 11:02:00</td>\n",
       "      <td>0 days 04:04:08.181818181</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Neuss Hbf</td>\n",
       "      <td>Störung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7 days 03:10:00</td>\n",
       "      <td>0 days 04:37:34.054054054</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train_station category  priority   total_duration  \\\n",
       "54          Dortmund Hbf  Störung       1.0 14 days 18:37:00   \n",
       "74        Düsseldorf Hbf  Störung       1.0 13 days 09:04:00   \n",
       "223             Köln Hbf  Störung       1.0 11 days 15:01:00   \n",
       "286              Münster  Störung       1.0 11 days 13:30:00   \n",
       "65          Duisburg Hbf  Störung       1.0 11 days 04:33:00   \n",
       "92             Essen Hbf  Störung       1.0 10 days 22:41:00   \n",
       "153                 Hamm  Störung       1.0 10 days 09:09:00   \n",
       "22            Bochum Hbf  Störung       1.0  9 days 01:11:00   \n",
       "275  Mülheim an der Ruhr  Störung       1.0  7 days 11:02:00   \n",
       "289            Neuss Hbf  Störung       1.0  7 days 03:10:00   \n",
       "\n",
       "             average_duration  total_interferences  \n",
       "54  0 days 04:55:30.833333333                   72  \n",
       "74  0 days 04:20:19.459459459                   74  \n",
       "223    0 days 04:21:34.687500                   64  \n",
       "286 0 days 04:52:06.315789473                   57  \n",
       "65  0 days 04:19:53.225806451                   62  \n",
       "92  0 days 04:10:10.476190476                   63  \n",
       "153 0 days 04:42:03.396226415                   53  \n",
       "22     0 days 04:20:37.200000                   50  \n",
       "275 0 days 04:04:08.181818181                   44  \n",
       "289 0 days 04:37:34.054054054                   37  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_lasting_interferences = short_lasting_interferences.sort_values(by=[\"category\", \"total_duration\", \"total_interferences\", \"priority\"], ascending=[True, False, False, True])\n",
    "short_lasting_interferences.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this last chapter we summarize our results by presenting our findings again. Furthermore we also like to indicate on which major assumptions these findings are based. Then we briefly sum up the most difficult problems tackled in the project. Finally we give an outlook how the project can be extended and how the certainty of the results can be further improved.\n",
    "\n",
    "### Findings\n",
    "\n",
    "#### Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Major Assumptions\n",
    "This section should briefly cover the most important assumptions that were made.\n",
    "\n",
    "#### The more delays the worse the station\n",
    "The findings in Datasource 2 require the assumption that the more delays a station has the worse the station is. This might not always be true. It is rather likely that f.e. the station Berlin Hbf has more delays than the station of Rostock. But for towns that have stations that have a comparable train frequency this assumption is likely to be true.\n",
    "\n",
    "#### One station per town\n",
    "For a town only the central train station was considered in Dataset 2, not all stations of a town.\n",
    "\n",
    "### Problems during the whole Project\n",
    "\n",
    "#### Corrupted ttl file of Datasource 1\n",
    "The most severe problem tackeled during the project was that Datasource 1 provides corrupted data. The ttl file containing the rdf graph with the connection times between the towns is syntactically false. Therefore a preprocessing was required before the graph could be parsed. The preprocessing contains replacing expressions using regexes and removing invalid signs. \n",
    "\n",
    "A relation in rdf basically consists of a triple of a *\\<subject\\>*, *\\<predicate\\>* and an *\\<object\\>* like f.e. *Erlangen* *IsConnectedTo* *Berlin*. \n",
    "\n",
    "The relation between source and destination with attributes like the driving time was also not correctly associated in rdf terms in the ttl file. For this reason attributes also had to be brought into relation with the corresponding connection by complex logical changes in the rdf file. \n",
    "\n",
    "By these changes the attributes could be brought into relation to its connection and the graph could be parsed correctly with rdflib.\n",
    "\n",
    "#### Contineous updates of Datasource 2\n",
    "Another problem was that the DB Timetable API provides potentially new informations every 30 minutes. Nethertheless some informations do not change that often (f.e. the delay cause *Bauarbeiten* are a time consuming task that lasts from days to months). Therefore one problem is the deduplication of events that were grasped multiple times. Also would it be nice to grasp the data contineously like f.e. every hour, but this what require an installation on a server that automatically calls the API as a scheduled task. This was not possible manually.\n",
    "\n",
    "#### XML representation of the data of Datasource 2\n",
    "The used endpoint of the DB Timetable API of Datasource 2 provides more information than just the delay causes in a XML representation. To retrieve only the needed data a XPATH query was used. \n",
    "\n",
    "### Outlook\n",
    "#### Contineous grasping of data from Datasource 2\n",
    "The actual dataset from Datasource 2 covers at the moment data of four different days. The data was requested about approximately the same time. An interesting enhancement would be to deploy the model to a server with much storage and call the DB Api automatically daily or hourly over a long time like f.e. a year. The current data is just a snapshot of the current state. Maybe it can be found that in the long term other stations are the ones that are the most potential for enhancements.\n",
    "\n",
    "#### Including multiple stations per town\n",
    "Some towns have multiple stations. In this report only the main train station of a town is covered. Covering other stations of towns in Dataset 2 would also provide further information.\n",
    "\n",
    "#### Comparing train connection times of Datasource 1 with real-time information of the DB Timetable API\n",
    "Furthermore the DB Timetable API provides other endpoints that provide further information of current connections. It would be interesting to compare the real average train connection times with the train connection times provided in Dataset 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Destination/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
